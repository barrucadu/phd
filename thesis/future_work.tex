\paragraph{Measuring the quality of test suites}
How do we come to believe that a test suite is strong evidence for the
correctness of some program?  Any testing regimen is only as good as
its tests.  For sequential programs, we can use the traditional metric
of code coverage.  Code which is not covered at all usually has more
bugs than code which is covered by even low-quality
tests\cite{ahmed2016}.  For concurrent programs, what metric do we
use?  If it is some notion of coverage, what is the space being
covered?  There are a few candidates:

\begin{itemize}
\item Schedule-sensitive branches are often unintentional and
  erroneous points of synchronisation between concurrent
  threads\cite{huang2015ssb}.  A good concurrency test suite should
  try all cases in a schedule-sensitive branch.

\item Shared state which is not guarded by appropriate synchronisation
  can lead to invalid or corrupt data.  If we have functions which
  operate on some mutable state of the same type, then a good
  concurrency test suite should check what happens when those states
  are shared and the functions executed concurrently.
\end{itemize}

Being able to identify cases where a concurrency test suite is lacking
could greatly help with improving the overall quality of a piece of
software.

\paragraph{Maximal causality reduction for \dejafu{}}
The MCR algorithm\cite{huang2015} explores a provably minimal number
of schedules required for completeness.  Typically this is orders of
magnitude fewer than dynamic partial-order reduction.  MCR is tricky
to implement in Haskell as it requires local determinism: the future
actions of a thread are determined solely by the prior actions of the
same thread and shared variables it has read.  Haskell breaks local
determinism with asynchronous exceptions, where one thread can kill
another.

MCR is described in terms of a core concurrent language of locks and
shared variables, which is much simpler than Haskell.  It may be
possible to implement a Haskell-MCR by translating Haskell execution
traces into a simpler form suitable for MCR\@.  For example,
asynchronous exceptions can be modelled by giving each thread an
`exception variable,' where throwing an exception to a thread writes
to that variable, and the thread checks the variable before each
action.

There is an open source MCR implementation for concurrent
Java\footnote{\url{https://github.com/parasol-aser/JMCR}}.

\paragraph{Accurately modelling delays in \dejafu{}}
There has been interest in using \dejafu{} to test distributed systems
where timing issues are
important\footnote{\url{https://github.com/barrucadu/dejafu/issues/130}}.
However, \dejafu{} currently has no notion of time.  A thread delaying
is treated just the same as a thread yielding, it has no further
effect on how threads are scheduled during testing.  Incorporating
time is difficult, as it comes down to forbidding executions which a
human would consider unreasonable.  Unreasonableness is not something
that can easily be measured, unlike the number of pre-emptive context
switches, yields, or scheduling points.

Perhaps the field of model checking has something to suggest here.  Or
perhaps there is some way to quantify and impose a bound on
unreasonableness.  Whatever the approach, solving this problem would
make \dejafu{} more useful for systems whose correctness depends on
real timing constraints.

\paragraph{Conditional properties in CoCo}
Speculate\cite{braquehais2017} discovers conditional equations and
inequalities automatically, which greatly expands the range of
properties which can be found.  This is useful as we see how our
functions behave in different situations, rather than just in general.
CoCo has a limited form of conditional properties, where it can use
preconditions on the seed, which must be supplied by the programmer.
However, it would be much more useful if CoCo could synthesise
preconditions, as Speculate does, to discover interesting cases
itself.

\paragraph{Term rewriting for CoCo}
Both QuickSpec\cite{smallbone2017} and Speculate\cite{braquehais2017}
use term rewriting to prune the discovered properties and to avoid
testing many cases.  This is difficult to do with concurrency, as
effects may be non-local, as is the case with relaxed
memory\cite{zhang2015} where writes to shared variables may be
delayed.  Such behaviours make the effect of composing two terms far
less predictable.  Even so, it may still be possible in some cases to
use something like term rewriting to prune properties.
