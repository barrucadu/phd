Concurrency is not in standard Haskell, so here we restrict our
interest to GHC\@.  In this chapter we give an overview of the
concurrency functionality we use.  These operations are available in
the \package{concurrency} library.  We cover the basic use of
concurrency~\sref{concurrent_haskell-threads}, the memory
model~\sref{concurrent_haskell-mmodel}, software transactional
memory~\sref{concurrent_haskell-stm}, and finally
exceptions~\sref{concurrent_haskell-exc}.

Throughout, we compare with the concurrency abstractions of Java and
Rust.  Java because it is a popular language which, like Haskell, has
exceptions.  Rust because its design borrows from the spirit of
functional languages.

\section{Threads and Mutable Variables}
\label{sec:concurrent_haskell-threads}

Threads let a program do multiple things at once.  Every program has
at least one thread, which starts where \verb|main| does and runs
until the program terminates.  A thread is the basic unit of
concurrency.  It lets us pretend that we're computing multiple things
at once.

\paragraph{Basic threading}
A thread can be started using the \verb|forkIO| function:

\begin{minted}{haskell}
forkIO :: IO () -> IO ThreadId
\end{minted}

This starts executing its argument in a separate thread.  It also
gives us back a \verb|ThreadId| value, which can be used to kill the
thread.  A thread can get its own \verb|ThreadId| with
\verb|myThreadId|:

\begin{minted}{haskell}
myThreadId :: IO ThreadId
\end{minted}

In Java, threads are created from classes implementing the
\verb|Runnable| interface.  The \verb|Thread| constructor creates a
new thread object from a \verb|Runnable|, but it does not start until
\verb|Thread.start| is called:

\begin{minted}{java}
Runnable runnable = /* ... */;
Thread thread = new Thread(myRunnable);
thread.start();
\end{minted}

The thread object itself fulfils the role of the Haskell
\verb|ThreadId| type.  Any point in the program can get a reference to
the current thread with the \verb|Thread.currentThread| static method:

\begin{minted}{java}
Thread me = Thread.currentThread();
\end{minted}

Rust supports both the Haskell and Java thread creation styles.  The
Haskell-style \verb|thread::spawn| function takes a closure to
execute, creates and immediately begins executing a thread, and
returns an identifier:

\begin{minted}{rust}
let thread = thread::spawn(|| { /* ... */ });
\end{minted}

Whereas the Java-style \verb|thread::Builder| interface allows
creating a thread without starting it.  In both cases, the compiler
gives an error if the closure captures a variable from its outer scope
without the appropriate move semantics.  Like Haskell and Java, a
thread can acquire a reference to the current thread:

\begin{minted}{rust}
let me = thread::current();
\end{minted}

\paragraph{Capabilities}
In a real machine, there are multiple processors and cores.  It may be that a
particular application of concurrency is only a net gain if every thread is
operating on a separate core, so that threads are not interrupting each other.
GHC uses a \emph{green threading} model, where Haskell threads are multiplexed
onto a much smaller number of operating system threads.  The number of operating
system threads is referred to as the number of \emph{capabilities} or
\emph{Haskell execution contexts}.  Only operating system threads have the
possibility of executing truly in parallel.

We can fork a thread to a particular OS thread with the \verb|forkOn|
function:

\begin{minted}{haskell}
forkOn :: Int -> IO () -> IO ThreadId
\end{minted}

The capability number is interpreted modulo the total number of OS
threads, which can be queried and set:

\begin{minted}{haskell}
getNumCapabilities :: IO Int
setNumCapabilities :: Int -> IO ()
\end{minted}

Neither Java nor Rust provide green threading.  Java does not specify
how its threads are mapped to OS threads but, on Linux, each Java
thread is an OS thread.  Rust specifies that its threads are OS
threads.

\paragraph{Scheduling}
The GHC scheduler is good, but sometimes we have domain knowledge which lets us
do better.  There are two ways to influence how threads are scheduled: we can
yield control to another thread, or delay the current thread for a period of
time:

\begin{minted}{haskell}
yield       :: IO ()
threadDelay :: Int -> IO ()
\end{minted}

In Java, we can use the \verb|Thread.yield| and \verb|Thread.sleep|
methods to affect scheduling.  We can also adjust the \emph{priority}
of a thread, where the initial priority is inherited from its creator.
Threads with higher priority are executed in preference to threads
with lower priority:

\begin{minted}{java}
Thread thread = /* ... */;
thread.setPriority(/* ... */);
\end{minted}

Rust has three ways to control scheduling.  It can yield with
\verb|thread::yield_now|, or delay with \verb|thread::sleep|, but it
can also \emph{park} the current thread.  When parked, a thread will
not execute until it is unparked by another thread.

\begin{minted}{rust}
thread::park() /* execution stops now */

/* from another thread */
reference_to_thread::unpark();
\end{minted}

There is also a variant of \verb|thread::park| with a timeout, which
provides a delay-unless-woken construct.  Haskell threads have no
notion of priority or parking.

\paragraph{Termination}
Both Java and Rust can use a thread handle to wait until that thread
terminates.  This is called \emph{joining}.  Joining blocks the
current thread until the referenced thread terminates.  Haskell cannot
do this.

\section{Shared Variables and the Memory Model}
\label{sec:concurrent_haskell-mmodel}

There are two main types of shared variable in GHC Haskell, with different
semantics.

\paragraph{The \texttt{IORef} type}
An \verb|IORef| is a mutable location in memory holding a Haskell
value.  It is similar to a normal reference variable in impure
languages:

\begin{minted}{haskell}
newIORef   :: a -> IO (IORef a)
readIORef  :: IORef a -> IO a
writeIORef :: IORef a -> a -> IO ()
\end{minted}

As Java is an impure language with no restriction on sharing, it has
no need for a type like \verb|IORef|.  Any thread can mutate any
reference that is in scope.  Rust does impose restrictions on
mutability and sharing, and provides a few different shared variable
types.  The closest to \verb|IORef a| is a reference-counting box
containing an atomically modifiable pointer:

\begin{minted}{rust}
let ptr = &mut /* ... */;
let shared = Arc::new(AtomicPtr::new(ptr));
\end{minted}

Threads can modify the pointer by cloning the shared \verb|Arc| value,
extracting the inner \verb|AtomicPtr|, and updating the value inside:

\begin{minted}{rust}
let shared_clone = shared.clone();
let thread = thread::spawn(move|| {
    shared_clone.store(/* ... */, Ordering::SeqCst);
});
\end{minted}

All mutation operations take as a parameter the type of memory
consistency to enforce, which we shall discuss shortly.

\paragraph{The \texttt{MVar} type}
An \verb|MVar| is a mutable location in memory with two possible
states: \emph{full}, holding a Haskell value, and \emph{empty},
holding no value.  An \verb|MVar| can be created in either state:

\begin{minted}{haskell}
newMVar      :: a -> IO (MVar a)
newEmptyMVar :: IO (MVar a)
\end{minted}

Writing to a full \verb|MVar| blocks until it is empty, and reading or taking
from an empty \verb|MVar| blocks until it is full.  There are also non-blocking
functions which return an indication of success:

\begin{minted}{haskell}
putMVar     :: MVar a -> a -> IO ()
readMVar    :: MVar a -> IO a
takeMVar    :: MVar a -> IO a

tryPutMVar  :: MVar a -> a -> IO Bool
tryReadMVar :: MVar a -> IO (Maybe a)
tryTakeMVar :: MVar a -> IO (Maybe a)
\end{minted}

The blocking behaviour of \verb|MVar|s means that computations can
become deadlocked.  For example, deadlock occurs if every thread tries
to take from the same \verb|MVar|, with no threads writing to it.
This can be detected, as we shall see in \cref{chp:dejafu}.  As there
are no blocking \verb|IORef| primitives, use of them cannot cause a
deadlock.

Java does not provide an exact analogue of \verb|MVar|, but it does
provide mutexes and semaphores which can be used to control access to
a shared resource:

\begin{minted}{java}
Semaphore sem = new Semaphore(/* initial quantity */);

/* from another thread */
sem.acquire(/* quantity */);
/* ... */
sem.release(/* quantity */);
\end{minted}

The Rust ``mutex'' type is more like the Haskell \verb|MVar| type, in
that it does not merely function as a lock but also guards a
reference:

\begin{minted}{rust}
let shared = Arc::new(Mutex::new(/* ... */));

let shared_clone = shared.clone();
let thread = thread::spawn(move|| {
    let mut unlocked = shared_clone.lock();
    /* ... */
});
\end{minted}

Locks are released when the unlocked value falls out of scope.  This
ensures that a thread cannot unlock a mutex and terminate with the
mutex still locked.  There is also a non-blocking
\verb|Mutex::try_lock| function.  Unlike Java, there is no way to
explicitly lock an unlocked mutex.  Mutexes are not exactly the same
as a Haskell \verb|MVar|, however they can be used in the
implementation of an \verb|MVar|.

\paragraph{Memory model}
Unlike the \verb|MVar|, \verb|IORef| operations are not
\emph{synchronised}.  Reads and writes between threads may be
re-ordered.  The documentation has this to say:

\begin{bquote}{Data.IORef module documentation\footnote{\url{https://hackage.haskell.org/package/base-4.10.0.0/docs/Data-IORef.html\#g:2}}}
  In a concurrent program, \verb|IORef| operations may appear out-of-order to
  another thread, depending on the memory model of the underlying processor
  architecture.  For example, on x86, loads can move ahead of stores.

  The implementation is required to ensure that reordering of memory operations
  cannot cause type-correct code to go wrong.  In particular, when inspecting
  the value read from an \verb|IORef|, the memory writes that created that value
  must have occurred from the point of view of the current thread.
\end{bquote}

For testing purposes, we support the Total Store Order~(TSO) and Partial Store
Order~(PSO) models~\sref{dejafu-execution}.  Many other operations are
synchronised, and act as a \emph{barrier} to re-ordering.  Reading or writing to
an \verb|MVar| does; executing an STM transaction does; throwing an asynchronous
exception does; and the atomic \verb|IORef| operations do:

\begin{minted}{haskell}
atomicWriteIORef  :: IORef a -> a -> IO ()
atomicModifyIORef :: IORef a -> (a -> (a, b)) -> IO b
\end{minted}

Java allows controlling the synchronisation on a per-variable basis.
Operations on normal shared variables may appear out-of-order to
different threads, however a \verb|volatile| variable will be
in-order:

\begin{minted}{java}
public volatile int sequentiallyConsistent = 0;
\end{minted}

As we saw in the \verb|IORef| segment, Rust operations which mutate
atomic values specify the memory consistency desired.  The weakest is
\verb|Relaxed|, which imposes no constraints, and the strongest is
\verb|SeqCst|, which imposes sequential consistency.

\paragraph{Compare-and-swap}
Modern processor architectures provide an atomic \emph{compare-and-swap}
instruction, which is typically used in implementing high-performance lock-free
algorithms.  The \package{atomic-primops} package exposes this to Haskell code:

\begin{minted}{haskell}
readForCAS :: IORef a -> IO (Ticket a)
peekTicket :: Ticket a -> a
\end{minted}

A \verb|Ticket| is a proof that a value has been observed inside an
\verb|IORef| at some prior point.  Given this proof, the programmer
can efficiently and atomically change the value inside the
\verb|IORef| later if it has not been modified:

\begin{minted}{haskell}
casIORef :: IORef a -> Ticket a -> a -> IO (Bool, Ticket a)
\end{minted}

There is also a variant of \verb|atomicModifyIORef| using compare-and-swap:

\begin{minted}{haskell}
atomicModifyIORefCAS :: IORef a -> (a -> (a, b)) -> IO b
\end{minted}

Both \verb|casIORef| and \verb|atomicModifyIORefCAS| are partially
synchronised operations which act as a barrier to re-ordering on that
particular \verb|IORef|, but not for others.

Java provides variants of all the primitive types which support
updating by compare-and-swap.  For example, the \verb|AtomicInteger|
type:

\begin{minted}{java}
private AtomicInteger count = new AtomicInteger(0);

public void increment() {
  count.incrementAndGet();
}
\end{minted}

The Rust atomic types provide compare-exchange in addition to
compare-and-swap.  Compare-exchange differs from compare-and-swap in
that the programmer specifies the desired memory consistency on
failure:

\begin{minted}{rust}
ptr.compare_and_swap(other, another, Ordering::SeqCst);
ptr.compare_exchange(other, another, Ordering::SeqCst, Ordering::Relaxed);
\end{minted}

\section{Software Transactional Memory}
\label{sec:concurrent_haskell-stm}

Shared variables are nice, until we need more than one.  As we can
only claim one \verb|MVar| atomically (or write to one \verb|IORef|
atomically), it seems we need to introduce additional synchronisation.
This is unwieldy and prone to bugs.

Software transactional memory~(STM) is the solution.  STM is based on
the idea of atomic \emph{transactions}.  An STM transaction consists
of one or more operations over a collection of \emph{transaction
  variables}, where a transaction may be aborted part-way through,
with all its effects rolled back.  Arbitrary effects are not
permitted, which is enforced by having a distinct type for STM actions
and not providing a function to turn \verb|IO| actions into \verb|STM|
actions.

Neither Java nor Rust provide an STM implementation in their standard
libraries, but there are third-party implementations.  However, as
Java and Rust are impure, these libraries cannot prevent the
programmer from performing arbitrary side-effects inside a
transaction.  If a transaction is rolled back, such side-effects may
be performed multiple times.  These STM library implementations
provide atomic transactions for specified operations, but they
\emph{cannot} provide the same guarantees as STM in Haskell.

\paragraph{The \texttt{TVar} type}
Transaction variables, or \verb|TVar|s, are yet another type of shared variable,
but with the difference that operating on them has a transactional effect:

\begin{minted}{haskell}
newTVar   :: a -> STM (TVar a)
readTVar  :: TVar a -> STM a
writeTVar :: TVar a -> a -> STM ()
\end{minted}

Transactions are atomic, so all reads will see a consistent state, and
in the presence of writes, intermediate states cannot be observed by
another thread.

\paragraph{Aborting and retrying}
If we read a \verb|TVar| and don't like the value it has, the
transaction can be aborted, and the thread will block until any of the
referenced \verb|TVar|s have been mutated:

\begin{minted}{haskell}
retry :: STM a
\end{minted}

We can also try executing a transaction, and do something else if it
retries:

\begin{minted}{haskell}
orElse :: STM a -> STM a -> STM a
\end{minted}

\paragraph{Executing transactions}
Transactions compose.  We can take small transactions and build bigger
transactions from them, and the whole is still executed atomically.

\begin{minted}{haskell}
atomically :: STM a -> IO a
\end{minted}

This means we can do complex state operations involving multiple shared
variables without worrying!

\section{Exceptions}
\label{sec:concurrent_haskell-exc}

Exceptions are a way to bail out of a computation early.  Exceptions can be
explicitly thrown within a single thread, these are \emph{synchronous}
exceptions, or thrown from one thread to another, these are \emph{asynchronous}
exceptions.

\paragraph{Throwing and catching}
The basic functions for dealing with exceptions are:

\begin{minted}{haskell}
catch :: Exception e => IO a -> (e -> IO a) -> IO a
throw :: Exception e => e -> IO a
\end{minted}

Where \verb|throw| causes the computation to jump back to the nearest
enclosing \verb|catch| capable of handling the particular exception.
If there is none, the thread terminates.  Exceptions belong to a
typeclass, rather than being a concrete type, so different
\verb|catch| functions can be nested, to handle different types of
exception.

Asynchronous exceptions can be thrown to another thread:

\begin{minted}{haskell}
throwTo    :: Exception e => ThreadId -> e -> IO ()
killThread :: ThreadId -> IO ()
\end{minted}

These functions block until the target thread is in an appropriate state to
receive the exception.  Asynchronous exceptions can be caught with \verb|catch|,
just like synchronous exceptions thrown with \verb|throw|.

The Java \verb|Thread.stop| method is like \verb|killThread|, but is
considered a bad idea and
deprecated\footnote{\url{https://docs.oracle.com/javase/7/docs/technotes/guides/concurrency/threadPrimitiveDeprecation.html}}.
The preferred approach is the \verb|Thread.interrupt| method, which
will either throw an exception or set a flag, depending on what the
target thread is doing.  For example, if the target thread is blocked
inside a \verb|Thread.sleep| call, it will receive an
\verb|InterruptedException|.

Rust does not provide any way to tell a thread to terminate.

\paragraph{Masking}
A thread has a masking state, which can be used to block exceptions
from other threads.  There are three masking states: \emph{unmasked},
in which a thread can have exceptions thrown to it;
\emph{interruptible}, in which a thread can only have exceptions
thrown to it if it is blocked; and \emph{uninterruptible}, in which a
thread cannot have exceptions thrown to it.

There are two functions to set the masking state.  These each execute a
computation in the new state, and pass it a function to run a subcomputation
with the original masking state:

\begin{minted}{haskell}
mask                :: ((forall a. IO a -> IO a) -> IO b) -> IO b
uninterruptibleMask :: ((forall a. IO a -> IO a) -> IO b) -> IO b
\end{minted}

When a thread is started, it inherits the masking state of its parent.  As the
parent may be masked, we can fork a thread with a function to run a
subcomputation with exceptions unmasked:

\begin{minted}{haskell}
forkIOWithUnmask :: ((forall a. IO a -> IO a) -> IO ()) -> IO ThreadId
forkOnWithUnmask :: Int -> ((forall a. IO a -> IO a) -> IO ()) -> IO ThreadId
\end{minted}

\paragraph{Software transactional memory}
STM can also use exceptions.  If an exception propagates uncaught to the top of
a transaction, that transaction is aborted.

\begin{minted}{haskell}
throwSTM :: Exception e => e -> STM a
catchSTM :: Exception e => STM a -> (e -> STM a) -> STM a
\end{minted}

The \verb|orElse| function does not catch exceptions.
