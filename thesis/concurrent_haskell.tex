In this chapter we give an overview of Concurrent
Haskell\cite{peytonjones1996,peytonjones2005}.  As we use Haskell for
our implementation language, we wish to support as much of Concurrent
Haskell as possible.  Concurrency is not in the Haskell standard, so
we are specifically considering GHC here.  These operations are
available in the \package{concurrency} library.  We cover the basic
use of concurrency~\sref{concurrent_haskell-threads}, the memory
model~\sref{concurrent_haskell-mmodel}, software transactional
memory~\sref{concurrent_haskell-stm}, and finally
exceptions~\sref{concurrent_haskell-exc}.

Throughout, we compare with the concurrency abstractions of
Java\cite{lea1996} and Rust\cite{rust2011}.  Java because it is a
popular language which, like Haskell, has exceptions.  Rust because
its design borrows from the spirit of functional languages.  Although
we use Haskell, there is nothing Haskell-specific in our results or
methods.

\section{Multithreading}
\label{sec:concurrent_haskell-threads}

Threads let a program do multiple things at once.  Every program has
at least one thread, which runs the main action of the program.  A
thread is the basic unit of concurrency.

\begin{listing}
\centering
\begin{cminted}{haskell}
forkIO     :: IO () -> IO ThreadId
myThreadId :: IO ThreadId
\end{cminted}
\caption{Basic threading operations in Haskell.}\label{lst:basic_haskell}
\end{listing}

Haskell's basic threading functions are shown in
\Cref{lst:basic_haskell}.  A thread can be started using the
\verb|forkIO| function, which starts executing its argument in a
separate thread and also gives us back a \verb|ThreadId| value, which
can be used to kill the thread.  A thread can get its own
\verb|ThreadId| using \verb|myThreadId|.

\begin{listing}
\centering
\begin{cminted}{java}
/* forkIO */
Runnable runnable = /* action */;
Thread thread = new Thread(runnable);
thread.start();

/* myThreadId */
Thread me = Thread.currentThread();
\end{cminted}
\caption{Basic threading operations in Java.}\label{lst:basic_java}
\end{listing}

In Java\cite{lea1996}, threads are created from classes implementing
the \verb|Runnable| interface, as shown in \Cref{lst:basic_java}.  The
\verb|Thread| constructor creates a new thread object from a
\verb|Runnable|, but it does not start until \verb|Thread.start| is
called.  The thread object itself fulfils the role of the Haskell
\verb|ThreadId| type.  A thread can get a reference to itself with the
\verb|Thread.currentThread| static method.

\begin{listing}
\centering
\begin{cminted}{rust}
/* Haskell style */
let thread = thread::spawn(/* closure */);

/* Java style */
let thread = thread::Builder::new().spawn(/* closure */);

/* myThreadId */
let me = thread::current();
\end{cminted}
\caption{Basic threading operations in Rust.}\label{lst:basic_rust}
\end{listing}

Rust\cite{rust2011} supports both the Haskell and Java thread creation
styles, as shown in \Cref{lst:basic_rust}.  The Haskell-style
\verb|thread::spawn| function takes a closure to execute, creates and
immediately begins executing a thread, and returns an identifier.  The
alternative Java-style \verb|thread::Builder| interface allows
creating a thread without starting it.  Rust enforces an
\emph{ownership type} model, and the compiler gives an error if a
thread closure captures a variable from its outer scope.

\paragraph{Capabilities}
In a real machine, there are multiple processors and cores.  It may be
that a particular application of concurrency is only a net gain if
each thread is operating on a separate core, so that threads are not
interrupting each other.  GHC uses a \emph{green threading} model,
where Haskell threads are multiplexed onto a much smaller number of
operating system threads\cite{marlow2009}.  The number of operating
system threads is referred to as the number of \emph{capabilities} or
\emph{Haskell execution contexts} (HECs)\cite{marlow2009}.  Only
operating system threads have the possibility of executing truly in
parallel.

\begin{listing}
\centering
\begin{cminted}{haskell}
forkOn             :: Int -> IO () -> IO ThreadId

getNumCapabilities :: IO Int
setNumCapabilities :: Int -> IO ()
\end{cminted}
\caption{Operating system threads in Haskell.}\label{lst:caps_haskell}
\end{listing}

We can fork a thread to run on a particular capability with the
\verb|forkOn| function, which takes a number identifying the
capability to use.  This capability number is interpreted modulo the
total number of capabilities, which can be queried and set.
\Cref{lst:caps_haskell} shows the capability functions.

Neither Java nor Rust provide green threading.  Java does not specify
how its threads are mapped to OS threads but, on Linux, each Java
thread is an OS thread.  Rust specifies that its threads are OS
threads.

\paragraph{Scheduling}
The GHC scheduler is necessarily general-purpose.  However, sometimes
we have domain knowledge which lets us do better.

\begin{listing}
\centering
\begin{cminted}{haskell}
yield       :: IO ()
threadDelay :: Int -> IO ()
\end{cminted}
\caption{Controlling thread scheduling in Haskell.}\label{lst:schedule_haskell}
\end{listing}

\Cref{lst:schedule_haskell} shows the two ways to influence how
threads are scheduled: (1) we can yield control to another thread, or
(2) we can delay the current thread for a period of time.

\begin{listing}
\centering
\begin{cminted}{java}
Thread thread = /* ... */;
thread.setPriority(/* new priority */);
\end{cminted}
\caption{Thread priority in Java.}\label{lst:schedule_java}
\end{listing}

In Java, we can use the \verb|Thread.yield| and \verb|Thread.sleep|
methods, shown in \Cref{lst:schedule_java}, to affect scheduling.  We
can also adjust the \emph{priority} of a thread, where the initial
priority is inherited from its creator.  Threads with higher priority
are executed in preference to threads with lower priority:

\begin{listing}[h!]
\centering
\begin{cminted}{rust}
thread::park() /* execution stops now */

/* from another thread */
reference_to_thread::unpark();
\end{cminted}
\caption{Thread parking and unparking in Rust.}\label{lst:schedule_rust}
\end{listing}

Rust has three ways to control scheduling.  In addition to yielding
and delaying, it can also \emph{park} the current thread, shown in
\Cref{lst:schedule_rust}.  When parked, a thread will not execute
until it is unparked by another thread.  There is a variant of
\verb|thread::park| with a timeout, which provides a
delay-unless-woken construct.

Haskell threads have no notion of parking.  However, parking is not an
essential primitive.  It can be implemented with what we have seen so
far.  We can associate with each thread an \verb|MVar|.  Parking
corresponds to \verb|takeMVar|.  Unparking corresponds to
\verb|tryPutMVar|.  Parking with a timeout can be implemented by
forking a thread to unpark after a delay.

Haskell threads have no notion of priority.  However, GHC uses a
round-robin scheduler, so one thread cannot starve another for
execution time.

\paragraph{Termination}
Both Java and Rust can use a thread handle to block until that thread
terminates.  This is called \emph{joining}.

Haskell provides no join operation, but one can be implemented using
by associating an \verb|MVar| with each thread, like parking.  Before
a thread terminates it will execute a \verb|putMVar|, and joining
corresponds to \verb|readMVar|.

\section{Shared State and the Memory Model}
\label{sec:concurrent_haskell-mmodel}

Concurrent Haskell uses a shared-memory model for communication
between threads.  There are two main types of shared variable, with
different semantics.

\paragraph{Shared mutable references}
An \verb|IORef| is a mutable location in memory holding a Haskell
value.  The API is shown in \Cref{lst:smref_haskell}.

\begin{listing}
\centering
\begin{cminted}{haskell}
newIORef   :: a -> IO (IORef a)
readIORef  :: IORef a -> IO a
writeIORef :: IORef a -> a -> IO ()
\end{cminted}
\caption{Shared mutable references in Haskell.}\label{lst:smref_haskell}
\end{listing}

Java is an impure language with no restriction on sharing, so it has
no need for a type like \verb|IORef|.  Any thread can mutate any
reference that is in scope.

\begin{listing}
\centering
\begin{cminted}{rust}
let ptr = &mut /* initial value */;
let shared = Arc::new(AtomicPtr::new(ptr));

let shared_clone = shared.clone();
let thread = thread::spawn(move|| {
    shared_clone.store(/* new value */, Ordering::SeqCst);
});
\end{cminted}
\caption{Shared mutable references in Rust.}\label{lst:smref_rust}
\end{listing}

Rust does impose restrictions on mutability and sharing, and provides
a few different shared variable types.  The closest to \verb|IORef| is
a reference-counting box containing an atomically modifiable pointer,
shown in \Cref{lst:smref_rust}.  Threads can modify the pointer by
cloning the shared \verb|Arc| value, extracting the inner
\verb|AtomicPtr|, and updating the value inside.  All mutation
operations take as a parameter the type of memory consistency to
enforce, which we shall discuss shortly. \label{page:rust_mem}.

\paragraph{Shared references under mutual exclusion}
An \verb|MVar| is a mutable location in memory with two possible
states: \emph{full}, holding a Haskell value, and \emph{empty},
holding no value.  An \verb|MVar| can be created in either state.  The
API is shown in \Cref{lst:mute_haskell}.

\begin{listing}
\centering
\begin{cminted}{haskell}
newMVar      :: a -> IO (MVar a)
newEmptyMVar :: IO (MVar a)

putMVar      :: MVar a -> a -> IO ()
readMVar     :: MVar a -> IO a
takeMVar     :: MVar a -> IO a

tryPutMVar   :: MVar a -> a -> IO Bool
tryReadMVar  :: MVar a -> IO (Maybe a)
tryTakeMVar  :: MVar a -> IO (Maybe a)
\end{cminted}
\caption{Mutual exclusion in Haskell.}\label{lst:mute_haskell}
\end{listing}

Writing to a full \verb|MVar| blocks until it is empty, and reading or
taking from an empty \verb|MVar| blocks until it is full.  There are
also non-blocking functions which return an indication of success.
The blocking behaviour of \verb|MVar|s means that computations can
become deadlocked.  For example, deadlock occurs if every thread tries
to take from the same \verb|MVar|, with no threads writing to it.
This form of deadlock can be detected, as we shall see in
\Cref{chp:dejafu}.  As there are no blocking \verb|IORef| primitives,
use of them cannot cause a deadlock.

\begin{listing}
\centering
\begin{cminted}{java}
Semaphore sem = new Semaphore(/* initial quantity */);

/* from another thread */
sem.acquire(/* quantity */);
/* ... */
sem.release(/* quantity */);
\end{cminted}
\caption{Mutual exclusion in Java.}\label{lst:mute_java}
\end{listing}

Java does not provide an exact analogue of \verb|MVar|, but it does
provide semaphores, shown in \Cref{lst:mute_java}, which can be used
to control access to a shared resource.

\begin{listing}
\centering
\begin{cminted}{rust}
let shared = Arc::new(Mutex::new(/* initial value */));

let shared_clone = shared.clone();
let thread = thread::spawn(move|| {
    let mut unlocked = shared_clone.lock();
    /* ... */
});
\end{cminted}
\caption{Mutual exclusion in Rust.}\label{lst:mute_rust}
\end{listing}

The Rust \verb|Mutex| type, shown in \Cref{lst:mute_rust}, is more
like the Haskell \verb|MVar| type.  It does not merely function as a
lock but also guards a reference.  Locks are released when the
unlocked value falls out of scope, ensuring that a thread cannot lock
a mutex and terminate without unlocking it.  There is also a
non-blocking \verb|Mutex::try_lock| function.  There is no way to
explicitly lock an unlocked mutex.

\paragraph{Memory model}
\verb|IORef| operations may appear to be re-ordered, depending on the
memory model of the underlying processor.  The documentation has this
to say:

\begin{displayquote}
  In a concurrent program, \verb|IORef| operations may appear out-of-order to
  another thread, depending on the memory model of the underlying processor
  architecture.  For example, on x86, loads can move ahead of stores.

  The implementation is required to ensure that reordering of memory operations
  cannot cause type-correct code to go wrong.  In particular, when inspecting
  the value read from an \verb|IORef|, the memory writes that created that value
  must have occurred from the point of view of the current thread.\cite{ioref}
\end{displayquote}

In our work, we support the Total Store Order~(TSO) and Partial Store
Order~(PSO) models~\sref{dejafu-execution}.  Many other operations are
\emph{synchronised}, and act as a \emph{barrier} to re-ordering.  Such
operations include reading or writing to an \verb|MVar|, executing an
STM transaction, and throwing an asynchronous exception.  There are
also atomic, synchronised, \verb|IORef| operations, shown in
\Cref{lst:atomic_haskell}.

\begin{listing}
\centering
\begin{cminted}{haskell}
atomicWriteIORef  :: IORef a -> a -> IO ()
atomicModifyIORef :: IORef a -> (a -> (a, b)) -> IO b
\end{cminted}
\caption{Atomic operations in Haskell.}\label{lst:atomic_haskell}
\end{listing}

Java allows specifying how individual variables should be
synchronised.  \Cref{lst:atomic_java} shows a \verb|volatile| integer.
Operations on normal shared variables may appear out-of-order to
different threads, however any operations on a \verb|volatile|
variable will be in-order.

\begin{listing}
\centering
\begin{cminted}{java}
public volatile int sequentiallyConsistent = 0;
\end{cminted}
\caption{Atomic operations in Java.}\label{lst:atomic_java}
\end{listing}

As we saw on page~\pageref{page:rust_mem}, Rust operations which
mutate atomic values specify the desired memory consistency.  The
weakest is \verb|Relaxed|, which imposes no constraints, and the
strongest is \verb|SeqCst|, which imposes sequential consistency.

\paragraph{Sequential consistency}
While relaxed memory models are used for performance, research
suggests that in languages which statically distinguish between shared
and thread-local state such as Haskell, sequential consistency can be
imposed for all shared state with little overhead\cite{vollmer2017}.
If implemented in Haskell, this policy would greatly simplify correct
use of \verb|IORef|s.

\paragraph{Compare-and-swap}
Modern processor architectures provide an atomic
\emph{compare-and-swap} instruction, which is typically used in
implementing lock-free algorithms\cite{dice2013}.  The
\package{atomic-primops} package provides a model of this instruction.

\begin{listing}
\centering
\begin{cminted}{haskell}
readForCAS :: IORef a -> IO (Ticket a)
peekTicket :: Ticket a -> a
casIORef   :: IORef a -> Ticket a -> a -> IO (Bool, Ticket a)
\end{cminted}
\caption{Compare-and-swap in Haskell.}\label{lst:cas_haskell}
\end{listing}

\Cref{lst:cas_haskell} shows compare-and-swap in Haskell.  A
\verb|Ticket| is a proof that a value has been observed inside an
\verb|IORef| at some prior point.  Given this proof, the programmer
can efficiently and atomically change the value inside the
\verb|IORef| later if it has not been modified.  The \verb|casIORef|
function is partially synchronised, acting as a barrier to re-ordering
of operations on that particular \verb|IORef|, but not constraining
other operations.

\begin{listing}
\centering
\begin{cminted}{java}
private AtomicInteger count = new AtomicInteger(0);

public void increment() {
  count.incrementAndGet();
}
\end{cminted}
\caption{Compare-and-swap in Java.}\label{lst:cas_java}
\end{listing}

Java provides variants of all the primitive types which support
compare-and-swap.  \Cref{lst:cas_java} shows the \verb|AtomicInteger|
type, an atomically modifiable 32-bit signed integer.

\begin{listing}
\centering
\begin{cminted}{rust}
ptr.compare_and_swap(other, another, Ordering::SeqCst);
ptr.compare_exchange(other, another, Ordering::SeqCst, Ordering::Relaxed);
\end{cminted}
\caption{Compare-and-swap in Rust.}\label{lst:cas_rust}
\end{listing}

The Rust atomic types provide compare-exchange, shown in
\Cref{lst:cas_rust}, in addition to compare-and-swap.
Compare-exchange differs from compare-and-swap in that the programmer
specifies the desired memory consistency on failure.  Specifying a
weaker memory consistency on failure may improve performance in some
cases, as synchronisation is expensive.

\section{Software Transactional Memory}
\label{sec:concurrent_haskell-stm}

Shared variables are nice, until we need more than one.  As we can
only claim one \verb|MVar| atomically (or write to one \verb|IORef|
atomically), it seems we need to introduce additional synchronisation.
This is unwieldy and prone to bugs.

\emph{Software transactional memory} (STM)\cite{harris2005,shavit1995}
is the solution.  STM is based on the idea of atomic
\emph{transactions}.  An STM transaction consists of one or more
operations over a collection of \emph{transaction variables}, where a
transaction may be aborted part-way through, with all its effects
rolled back.  Arbitrary effects are not permitted, which is enforced
by having a distinct type for STM actions.

Neither Java nor Rust provide an STM implementation in their standard
libraries, but there are third-party implementations.  However, as
Java and Rust are impure, these libraries cannot prevent the
programmer from performing arbitrary effects inside a transaction.
These STM library implementations provide atomic transactions for
specified operations, but they \emph{cannot} provide the same
guarantees as STM in Haskell.

\paragraph{Transactional variables}
The \verb|TVar| type is yet another type of shared variable, but with
the difference that operating on them has a transactional effect.  The
API is shown in \Cref{lst:tvars_haskell}.

\begin{listing}
\centering
\begin{cminted}{haskell}
newTVar   :: a -> STM (TVar a)
readTVar  :: TVar a -> STM a
writeTVar :: TVar a -> a -> STM ()
\end{cminted}
\caption{Transactional variables in Haskell.}\label{lst:tvars_haskell}
\end{listing}

Transactions are atomic, so all reads will see a consistent state, and
in the presence of writes, intermediate states cannot be observed by
another thread.

\paragraph{Aborting and retrying}
If we read a \verb|TVar| and don't like the value it has, the
transaction can be aborted.  The thread will then block until any of
the referenced \verb|TVar|s have been mutated.  We can also try
executing a transaction, and do something else if it retries, as shown
in \Cref{lst:orelse_haskell}.

\begin{listing}
\centering
\begin{cminted}{haskell}
retry  :: STM a
orElse :: STM a -> STM a -> STM a
\end{cminted}
\caption{Aborting and retrying transactions in Haskell.}\label{lst:orelse_haskell}
\end{listing}

\paragraph{Executing transactions}
Transactions compose.  We can take small transactions and build bigger
transactions from them, and the whole is still executed atomically, as
shown in \Cref{lst:atomically_haskell}.

\begin{listing}
\centering
\begin{cminted}{haskell}
atomically :: STM a -> IO a
\end{cminted}
\caption{Executing transactions in Haskell.}\label{lst:atomically_haskell}
\end{listing}

This means we can do complex state operations involving multiple
shared variables without worrying about atomicity.  However, using STM
requires the program to be structured in a way which separates state
modifications from other \verb|IO|.  Furthermore, due to how
transactions are aborted and restarted when a conflict occurs, large
transactions can be slow\cite{le2015}.

\section{Exceptions}
\label{sec:concurrent_haskell-exc}

Exceptions are a way to bail out of a computation early.  Exceptions can be
explicitly thrown within a single thread, these are \emph{synchronous}
exceptions, or thrown from one thread to another, these are \emph{asynchronous}
exceptions.

\paragraph{Throwing and catching}
The basic functions for dealing with exceptions are throwing and
catching.  The API is shown in \Cref{lst:excs_haskell}.

\begin{listing}
\centering
\begin{cminted}{haskell}
catch :: Exception e => IO a -> (e -> IO a) -> IO a
throw :: Exception e => e -> IO a
\end{cminted}
\caption{Exceptions in Haskell.}\label{lst:excs_haskell}
\end{listing}

Throwing an exception causes the computation to jump back to the
nearest enclosing suitable exception handler.  If there is none, the
thread terminates.  Haskell exceptions belong to a typeclass, rather
than having a specific type, so different \verb|catch| functions can
be nested, to handle different types of exception.

\begin{listing}
\centering
\begin{cminted}{java}
public void createFile(String path, String text) throws IOException {
  FileWriter writer = new FileWriter(path, true);
  writer.write(text);
  writer.close();
}
\end{cminted}
\caption{Checked exceptions in Java.}\label{lst:excs_java}
\end{listing}

In addition to Haskell-style exceptions, Java supports \emph{checked
  exceptions}, shown in \Cref{lst:excs_java}.  If a method can throw
(or propagate) a checked exception, this appears in the type
signature.  Checked exceptions statically enforce exception handling,
but are often regarded as cumbersome.  The Haskell type system has no
equivalent of checked exceptions.  If a Haskell programmer wants
something like a checked exception, they use a type such as
\verb|Either| to indicate success or failure.

\begin{listing}
\centering
\begin{cminted}{rust}
let result = panic::catch_unwind(|| {
    panic!("oh no!");
});
\end{cminted}
\caption{Panics in Rust.}\label{lst:excs_rust}
\end{listing}

Rust does not really have exceptions.  The \verb|panic| function,
shown in \Cref{lst:excs_rust}, raises an error which, if uncaught,
kills the current thread.  The \verb|catch_unwind| function can be
used to execute a closure and recover from a panic, but it is not
guaranteed to catch all panics\cite{rust2018}, making panics
unsuitable as a general control-flow mechanism.  The typical Rust
approach is, like Haskell, to return a type indicating success or
failure.

\begin{listing}
\centering
\begin{cminted}{haskell}
throwTo    :: Exception e => ThreadId -> e -> IO ()
killThread :: ThreadId -> IO ()
\end{cminted}
\caption{Asynchronous exceptions in Haskell.}\label{lst:excsa_haskell}
\end{listing}

In addition to \emph{synchronous} exceptions, Haskell has
\emph{asynchronous} exceptions, shown in \Cref{lst:excsa_haskell}
which can be thrown to another thread.  These functions block until
the target thread is in an appropriate state to receive the exception.
Asynchronous exceptions can be caught with \verb|catch|, just like
synchronous exceptions thrown with \verb|throw|.

The Java \verb|Thread.stop| method is similar to \verb|killThread|,
but is considered a bad idea and deprecated, as it causes the target
thread to immediately release any locks it holds\cite{oracle2017}.
The preferred approach is the \verb|Thread.interrupt| method, which
will either throw an exception or set a flag, depending on what the
target thread is doing.  For example, if the target thread is blocked
inside a \verb|Thread.sleep| call, it will receive an
\verb|InterruptedException|.

Rust does not provide any way to tell a thread to terminate.

\paragraph{Masking}
A thread has a masking state, which can be used to block exceptions
from other threads.  There are three masking states: \emph{unmasked},
in which a thread can have exceptions thrown to it;
\emph{interruptible}, in which a thread can only have exceptions
thrown to it if it is blocked; and \emph{uninterruptible}, in which a
thread cannot have exceptions thrown to it.

\begin{listing}
\centering
\begin{cminted}{haskell}
forkIOWithUnmask    :: ((forall a. IO a -> IO a) -> IO ()) -> IO ThreadId
forkOnWithUnmask    :: Int -> ((forall a. IO a -> IO a) -> IO ()) -> IO ThreadId

mask                :: ((forall a. IO a -> IO a) -> IO b) -> IO b
uninterruptibleMask :: ((forall a. IO a -> IO a) -> IO b) -> IO b
\end{cminted}
\caption{Masking exceptions in Haskell.}\label{lst:excm_haskell}
\end{listing}

There are two functions to set the masking state.  These each execute
a computation in the new state, and pass it a function to run a
subcomputation with the original masking state.  When a thread is
started, it inherits the masking state of its parent.  As the parent
may be masked, we can fork a thread with a function to run a
subcomputation with exceptions unmasked.  The API is shown in
\Cref{lst:excm_haskell}.

\paragraph{Software transactional memory}
STM can also use exceptions, as shown in \Cref{lst:excstm_haskell}.
If an exception propagates uncaught to the top of a transaction, that
transaction is aborted.

\begin{listing}
\centering
\begin{cminted}{haskell}
throwSTM :: Exception e => e -> STM a
catchSTM :: Exception e => STM a -> (e -> STM a) -> STM a
\end{cminted}
\caption{STM exceptions in Haskell.}\label{lst:excstm_haskell}
\end{listing}

The \verb|orElse| function does not catch exceptions.
