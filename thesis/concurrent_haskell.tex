In this chapter we give an overview of Concurrent
Haskell\cite{peytonjones2005,peytonjones1996}.  We use Haskell as the
implementation language, and the source of the concurrency abstraction
we target, in this thesis.  Concurrency is not in the Haskell
standard, the operations we discuss are available in GHC and may not
be in other compilers.  We cover the basic use of
concurrency~\sref{concurrent_haskell-threads}, the memory
model~\sref{concurrent_haskell-mmodel}, software transactional
memory~\sref{concurrent_haskell-stm}, and
exceptions~\sref{concurrent_haskell-exc}.  We then walk through the
development of a small example
program~\sref{concurrent_haskell-example}.

Throughout, we compare with the concurrency abstractions of
Java\cite{lea1996} and Rust\cite{rust2011}.  Java because it is a
popular language which, like Haskell, has exceptions.  Rust because
its design borrows from the spirit of functional languages.  Although
we use Haskell, there is nothing Haskell-specific in our results or
methods.

\section{Multithreading}
\label{sec:concurrent_haskell-threads}

Threads let a program do multiple things at once.  Every program has
at least one thread, which runs the main action of the program.  A
thread is the basic unit of concurrency.

\begin{listing}
\centering
\begin{cminted}{haskell}
forkIO     :: IO () -> IO ThreadId
myThreadId :: IO ThreadId
\end{cminted}
\caption{Basic threading operations in Haskell.}\label{lst:basic_haskell}
\end{listing}

Haskell's basic threading functions are shown in
\Cref{lst:basic_haskell}.  A thread can be started using the
\verb|forkIO| function, which starts executing its argument in a
separate thread and also gives us back a \verb|ThreadId| value, which
can be used to kill the thread.  A thread can get its own
\verb|ThreadId| using \verb|myThreadId|.

\begin{listing}
\centering
\begin{cminted}{java}
/* forkIO */
Runnable runnable = /* action */;
Thread thread = new Thread(runnable);
thread.start();

/* myThreadId */
Thread me = Thread.currentThread();
\end{cminted}
\caption{Basic threading operations in Java.}\label{lst:basic_java}
\end{listing}

In Java\cite{lea1996}, threads are created from classes implementing
the \verb|Runnable| interface, as shown in \Cref{lst:basic_java}.  The
\verb|Thread| constructor creates a new thread object from a
\verb|Runnable|, but it does not start until \verb|Thread.start| is
called.  The thread object itself fulfils the role of the Haskell
\verb|ThreadId| type.  A thread can get a reference to itself with the
\verb|Thread.currentThread| static method.

\begin{listing}
\centering
\begin{cminted}{rust}
/* Haskell style */
let thread = thread::spawn(/* closure */);

/* Java style */
let thread = thread::Builder::new().spawn(/* closure */);

/* myThreadId */
let me = thread::current();
\end{cminted}
\caption{Basic threading operations in Rust.}\label{lst:basic_rust}
\end{listing}

Rust\cite{rust2011} supports both the Haskell and Java thread creation
styles, as shown in \Cref{lst:basic_rust}.  The Haskell-style
\verb|thread::spawn| function takes a closure to execute, creates and
immediately begins executing a thread, and returns an identifier.  The
alternative Java-style \verb|thread::Builder| interface allows
creating a thread without starting it.  Rust enforces an
\emph{ownership type} system.  The compiler gives an error if a thread
closure captures a variable from its outer scope which is used later
in the outer scope.  Preventing variables from being used across
scopes is the source of much of Rust's memory safety.

\paragraph{Capabilities}
In a real machine, there are multiple processors and cores.  It may be
that a particular application of concurrency is only a net gain if
each thread is operating on a separate core, so that threads are not
interrupting each other.  GHC uses a \emph{green threading} model,
where Haskell threads are multiplexed onto a much smaller number of
operating system threads\cite{marlow2009}.  The number of operating
system threads is referred to as the number of \emph{capabilities} or
\emph{Haskell execution contexts} (HECs)\cite{marlow2009}.  Only
operating system threads have the possibility of executing truly in
parallel.

\begin{listing}
\centering
\begin{cminted}{haskell}
forkOn             :: Int -> IO () -> IO ThreadId

getNumCapabilities :: IO Int
setNumCapabilities :: Int -> IO ()
\end{cminted}
\caption{Operating system threads in Haskell.}\label{lst:caps_haskell}
\end{listing}

We can fork a thread to run on a particular capability with the
\verb|forkOn| function, which takes a number identifying the
capability to use.  This capability number is interpreted modulo the
total number of capabilities, which can be queried and set.
\Cref{lst:caps_haskell} shows the capability functions.

Neither Java nor Rust provide green threading.  Java does not specify
how its threads are mapped to OS threads but, on Linux, each Java
thread is an OS thread.  Rust specifies that its threads are OS
threads.

\paragraph{Scheduling}
The GHC scheduler is necessarily general-purpose.  However, sometimes
we have domain knowledge which lets us do better.

\begin{listing}
\centering
\begin{cminted}{haskell}
yield       :: IO ()
threadDelay :: Int -> IO ()
\end{cminted}
\caption{Controlling thread scheduling in Haskell.}\label{lst:schedule_haskell}
\end{listing}

\Cref{lst:schedule_haskell} shows the two ways to influence how
threads are scheduled: (1) we can yield control to another thread, or
(2) we can delay the current thread for a period of time.

\begin{listing}
\centering
\begin{cminted}{java}
Thread thread = /* ... */;
thread.setPriority(/* new priority */);
\end{cminted}
\caption{Thread priority in Java.}\label{lst:schedule_java}
\end{listing}

In Java, we can use the \verb|Thread.yield| and \verb|Thread.sleep|
methods, shown in \Cref{lst:schedule_java}, to affect scheduling.  We
can also adjust the \emph{priority} of a thread, where the initial
priority is inherited from its creator.  Threads with higher priority
are executed in preference to threads with lower priority.  Haskell
threads have no notion of priority.  However, GHC uses a round-robin
scheduler, so no one thread can starve another.

\begin{listing}[h!]
\centering
\begin{cminted}{rust}
thread::park() /* execution stops now */

/* from another thread */
reference_to_thread::unpark();
\end{cminted}
\caption{Thread parking and unparking in Rust.}\label{lst:schedule_rust}
\end{listing}

Rust has three ways to control scheduling.  In addition to yielding
and delaying, it can also \emph{park} the current thread, shown in
\Cref{lst:schedule_rust}.  When parked, a thread will not execute
until it is unparked by another thread.  There is a variant of
\verb|thread::park| with a timeout, which provides a
delay-unless-woken construct.

Haskell threads have no notion of parking.  However, parking is not an
essential primitive.  It can be implemented by associating an
\verb|MVar|~\sref{concurrent_haskell-mmodel} with each thread.
Parking corresponds to \verb|takeMVar|.  Unparking corresponds to
\verb|tryPutMVar|.  Parking with a timeout can be implemented by
forking a thread to unpark after a delay.

\paragraph{Termination}
Both Java and Rust can use a thread handle to block until that thread
terminates.  This is called \emph{joining}.  Haskell provides no join
operation, but one can be implemented using by associating an
\verb|MVar| with each thread, like parking.  Before a thread
terminates it will execute a \verb|putMVar|, and joining corresponds
to \verb|readMVar|.

\section{Shared State and the Memory Model}
\label{sec:concurrent_haskell-mmodel}

Concurrent Haskell uses a shared-memory model for communication
between threads.  There are two main types of shared variable, with
different semantics.

\paragraph{Shared mutable references}
An \verb|IORef| is a mutable location in memory holding a Haskell
value.  The API is shown in \Cref{lst:smref_haskell}.

\begin{listing}
\centering
\begin{cminted}{haskell}
newIORef   :: a -> IO (IORef a)
readIORef  :: IORef a -> IO a
writeIORef :: IORef a -> a -> IO ()
\end{cminted}
\caption{Shared mutable references in Haskell.}\label{lst:smref_haskell}
\end{listing}

Java is an impure language with no restriction on sharing, so it has
no need for a type like \verb|IORef|.  Any thread can mutate any
reference that is in scope.

\begin{listing}
\centering
\begin{cminted}{rust}
let ptr = &mut /* initial value */;
let shared = Arc::new(AtomicPtr::new(ptr));

let shared_clone = shared.clone();
let thread = thread::spawn(move|| {
    shared_clone.store(/* new value */, Ordering::SeqCst);
});
\end{cminted}
\caption{Shared mutable references in Rust.}\label{lst:smref_rust}
\end{listing}

Rust does impose restrictions on mutability and sharing, and provides
a few different shared variable types.  The closest to \verb|IORef| is
a reference-counting box containing an atomically modifiable pointer,
shown in \Cref{lst:smref_rust}.  Threads can modify the pointer by
cloning the shared \verb|Arc| value, extracting the inner
\verb|AtomicPtr|, and updating the value inside.  All mutation
operations take as a parameter the type of memory consistency to
enforce, which we shall discuss shortly. \label{page:rust_mem}

\paragraph{Shared references under mutual exclusion}
An \verb|MVar| is a mutable location in memory with two possible
states: \emph{full}, holding a Haskell value, and \emph{empty},
holding no value.  An \verb|MVar| can be created in either state.  The
API is shown in \Cref{lst:mute_haskell}.

\begin{listing}
\centering
\begin{cminted}{haskell}
newMVar      :: a -> IO (MVar a)
newEmptyMVar :: IO (MVar a)

putMVar      :: MVar a -> a -> IO ()
readMVar     :: MVar a -> IO a
takeMVar     :: MVar a -> IO a

tryPutMVar   :: MVar a -> a -> IO Bool
tryReadMVar  :: MVar a -> IO (Maybe a)
tryTakeMVar  :: MVar a -> IO (Maybe a)
\end{cminted}
\caption{Mutual exclusion in Haskell.}\label{lst:mute_haskell}
\end{listing}

Writing to a full \verb|MVar| blocks until it is empty, and reading or
taking from an empty \verb|MVar| blocks until it is full.  There are
also non-blocking functions which return an indication of success.
The blocking behaviour of \verb|MVar|s means that computations can
become deadlocked.  For example, deadlock occurs if every thread tries
to take from the same \verb|MVar|, with no threads writing to it.
This form of deadlock can be detected, as we shall see in
\Cref{chp:dejafu}.

\begin{listing}
\centering
\begin{cminted}{java}
Semaphore sem = new Semaphore(/* initial quantity */);

/* from another thread */
sem.acquire(/* quantity */);
/* ... */
sem.release(/* quantity */);
\end{cminted}
\caption{Mutual exclusion in Java.}\label{lst:mute_java}
\end{listing}

Java does not provide an exact analogue of \verb|MVar|, but it does
provide semaphores\cite{ewd123}, shown in \Cref{lst:mute_java}, which
can be used to control access to a shared resource.

\begin{listing}
\centering
\begin{cminted}{rust}
let shared = Arc::new(Mutex::new(/* initial value */));

let shared_clone = shared.clone();
let thread = thread::spawn(move|| {
    let mut unlocked = shared_clone.lock();
    /* ... */
});
\end{cminted}
\caption{Mutual exclusion in Rust.}\label{lst:mute_rust}
\end{listing}

The Rust \verb|Mutex| type, shown in \Cref{lst:mute_rust}, is more
like the Haskell \verb|MVar| type.  It does not merely function as a
lock but also guards a reference.  Locks are released when the
unlocked value falls out of scope, ensuring that a thread cannot lock
a mutex and terminate without unlocking it.  There is also a
non-blocking \verb|Mutex::try_lock| function.  There is no way to
explicitly lock an unlocked mutex.

\paragraph{Memory model}
\verb|IORef| operations may appear to be re-ordered, depending on the
memory model of the underlying processor.  The documentation has this
to say:

\begin{displayquote}
  In a concurrent program, \verb|IORef| operations may appear out-of-order to
  another thread, depending on the memory model of the underlying processor
  architecture.  For example, on x86, loads can move ahead of stores.

  The implementation is required to ensure that reordering of memory operations
  cannot cause type-correct code to go wrong.  In particular, when inspecting
  the value read from an \verb|IORef|, the memory writes that created that value
  must have occurred from the point of view of the current thread.\cite{data_ioref}
\end{displayquote}

Many non-\verb|IORef| operations are \emph{synchronised}, and act as a
\emph{barrier} to re-ordering.  Such operations include reading from
or writing to an \verb|MVar|, executing a software
transaction~\sref{concurrent_haskell-stm}, and throwing an
asynchronous exception~\sref{concurrent_haskell-exc}.  There are also
synchronised \verb|IORef| operations, shown in
\Cref{lst:atomic_haskell}.  In our work, we support the Total Store
Order~(TSO)\cite{owens2009} and Partial Store Order~(PSO)\cite{sparc}
models~\sref{dejafu-execution}.

\begin{listing}
\centering
\begin{cminted}{haskell}
atomicWriteIORef  :: IORef a -> a -> IO ()
atomicModifyIORef :: IORef a -> (a -> (a, b)) -> IO b
\end{cminted}
\caption{Atomic operations in Haskell.}\label{lst:atomic_haskell}
\end{listing}

Java allows specifying how individual variables should be
synchronised.  \Cref{lst:atomic_java} shows a \verb|volatile| integer.
Operations on normal variables may appear out-of-order to different
threads, however any operations on a \verb|volatile| variable will be
in-order.

\begin{listing}
\centering
\begin{cminted}{java}
public volatile int sequentiallyConsistent = 0;
\end{cminted}
\caption{Atomic operations in Java.}\label{lst:atomic_java}
\end{listing}

As we saw on page~\pageref{page:rust_mem}, Rust operations which
mutate atomic values specify the desired memory consistency.  The
weakest is \verb|Relaxed|, which imposes no constraints, and the
strongest is \verb|SeqCst|, which imposes sequential consistency.

\paragraph{Sequential consistency}
While relaxed memory models are used for performance, research
suggests that in languages which statically distinguish between shared
and thread-local state such as Haskell, sequential consistency can be
imposed for all shared state with little overhead\cite{vollmer2017}.
If implemented in Haskell, this policy would greatly simplify correct
use of \verb|IORef|s.

\paragraph{Compare-and-swap}
Modern processor architectures provide an atomic
\emph{compare-and-swap} instruction, which is typically used in
implementing lock-free algorithms\cite{dice2013}.  The
atomic-primops package\cite{atomic_primops} provides a model of this
instruction.

\begin{listing}
\centering
\begin{cminted}{haskell}
readForCAS :: IORef a -> IO (Ticket a)
peekTicket :: Ticket a -> a
casIORef   :: IORef a -> Ticket a -> a -> IO (Bool, Ticket a)
\end{cminted}
\caption{Compare-and-swap in Haskell.}\label{lst:cas_haskell}
\end{listing}

\Cref{lst:cas_haskell} shows compare-and-swap in Haskell.  A
\verb|Ticket| is a proof that a value has been observed inside an
\verb|IORef| at some prior point.  Given this proof, the programmer
can efficiently and atomically change the value inside the
\verb|IORef| later if it has not been modified.  The \verb|casIORef|
function is partially synchronised, acting as a barrier to re-ordering
of operations on that particular \verb|IORef|, but not constraining
other operations.

\begin{listing}
\centering
\begin{cminted}{java}
private AtomicInteger count = new AtomicInteger(0);

public void increment() {
  count.incrementAndGet();
}
\end{cminted}
\caption{Compare-and-swap in Java.}\label{lst:cas_java}
\end{listing}

Java provides an ``atomic'' variant of each primitive type.  These
atomic types support compare-and-swap.  \Cref{lst:cas_java} shows the
\verb|AtomicInteger| type, an atomically modifiable 32-bit signed
integer.

\begin{listing}
\centering
\begin{cminted}{rust}
ptr.compare_and_swap(other, another, Ordering::SeqCst);
ptr.compare_exchange(other, another, Ordering::SeqCst, Ordering::Relaxed);
\end{cminted}
\caption{Compare-and-swap in Rust.}\label{lst:cas_rust}
\end{listing}

The Rust atomic types provide compare-exchange, shown in
\Cref{lst:cas_rust}, in addition to compare-and-swap.
Compare-exchange differs from compare-and-swap in that the programmer
specifies the desired memory consistency on failure.  Specifying a
weaker memory consistency on failure may improve performance in some
cases, as synchronisation is expensive.

\section{Software Transactional Memory}
\label{sec:concurrent_haskell-stm}

Shared variables are nice, until we need more than one.  As we can
only claim one \verb|MVar| atomically (or write to one \verb|IORef|
atomically), it seems we need to introduce additional synchronisation.
This is unwieldy and prone to bugs.  \emph{Software transactional
  memory} (STM)\cite{harris2005,shavit1995} is the solution.  STM is
based on the idea of atomic \emph{transactions}.  A transaction
consists of one or more operations over a collection of
\emph{transaction variables}, where a transaction may be aborted
part-way through, with all its effects rolled back.  Arbitrary effects
are not permitted, which is enforced by having a distinct type for STM
actions.

Neither Java nor Rust provide an STM implementation in their standard
libraries, but there are third-party implementations.  However, as
Java and Rust are impure, these libraries cannot prevent the
programmer from performing arbitrary effects inside a transaction.
These STM library implementations provide atomic transactions for
specified operations, but they \emph{cannot} provide the same
guarantees as STM in Haskell.

\paragraph{Transactional variables}
The \verb|TVar| type is yet another type of shared variable, but with
the difference that operating on them has a transactional effect.  The
API is shown in \Cref{lst:tvars_haskell}.

\begin{listing}
\centering
\begin{cminted}{haskell}
newTVar   :: a -> STM (TVar a)
readTVar  :: TVar a -> STM a
writeTVar :: TVar a -> a -> STM ()
\end{cminted}
\caption{Transactional variables in Haskell.}\label{lst:tvars_haskell}
\end{listing}

Transactions are atomic, so all reads will see a consistent state and,
in the presence of writes, intermediate states cannot be observed by
another thread.

\paragraph{Aborting and retrying}
If we read a \verb|TVar| and do not like the value it has, the
transaction can be aborted.  The thread will then block until any of
the referenced \verb|TVar|s have been mutated.  We can also try
executing a transaction, and do something else if it retries, as shown
in \Cref{lst:orelse_haskell}.

\begin{listing}
\centering
\begin{cminted}{haskell}
retry  :: STM a
orElse :: STM a -> STM a -> STM a
\end{cminted}
\caption{Aborting and retrying transactions in Haskell.}\label{lst:orelse_haskell}
\end{listing}

\paragraph{Executing transactions}
Transactions compose.  We can take small transactions and build bigger
transactions from them, and the whole is still executed atomically, as
shown in \Cref{lst:atomically_haskell}.

\begin{listing}
\centering
\begin{cminted}{haskell}
atomically :: STM a -> IO a
\end{cminted}
\caption{Executing transactions in Haskell.}\label{lst:atomically_haskell}
\end{listing}

This means we can do complex state operations involving multiple
shared variables without worrying about atomicity.  However, using STM
requires the program to be structured in a way which separates state
modifications from other IO operations.  Furthermore, due to how
transactions are aborted and restarted when a conflict occurs, large
transactions can be slow\cite{le2015}.

\section{Exceptions}
\label{sec:concurrent_haskell-exc}

Exceptions are a way to bail out of a computation early.  Exceptions can be
explicitly thrown within a single thread, these are \emph{synchronous}
exceptions, or thrown from one thread to another, these are \emph{asynchronous}
exceptions.

\paragraph{Throwing and catching}
The basic functions for dealing with exceptions are throwing and
catching.  The API is shown in \Cref{lst:excs_haskell}.

\begin{listing}
\centering
\begin{cminted}{haskell}
catch :: Exception e => IO a -> (e -> IO a) -> IO a
throw :: Exception e => e -> IO a
\end{cminted}
\caption{Exceptions in Haskell.}\label{lst:excs_haskell}
\end{listing}

Throwing an exception causes the computation to jump back to the
nearest enclosing suitable exception handler.  If there is none, the
thread terminates.  Haskell exceptions belong to a typeclass, rather
than having a specific type, so different \verb|catch| functions can
be nested, to handle different types of exception.

\begin{listing}
\centering
\begin{cminted}{java}
public void createFile(String path, String text) throws IOException {
  FileWriter writer = new FileWriter(path, true);
  writer.write(text);
  writer.close();
}
\end{cminted}
\caption{Checked exceptions in Java.}\label{lst:excs_java}
\end{listing}

In addition to Haskell-style exceptions, Java supports \emph{checked
  exceptions}, shown in \Cref{lst:excs_java}.  If a method can throw
(or propagate) a checked exception, this appears in the type
signature.  Checked exceptions statically enforce exception handling,
but are often regarded as cumbersome.  The Haskell type system has no
equivalent of checked exceptions.  If a Haskell programmer wants
something like a checked exception, they use a type such as
\verb|Either| to indicate success or failure.

\begin{listing}
\centering
\begin{cminted}{rust}
let result = panic::catch_unwind(|| {
    panic!("oh no!");
});
\end{cminted}
\caption{Panics in Rust.}\label{lst:excs_rust}
\end{listing}

Rust does not really have exceptions.  The \verb|panic| function,
shown in \Cref{lst:excs_rust}, raises an error which, if uncaught,
kills the current thread.  The \verb|catch_unwind| function can be
used to execute a closure and recover from a panic, but it is not
guaranteed to catch all panics\cite{catch_unwind}, making panics
unsuitable as a general control-flow mechanism.  The typical Rust
approach is, like Haskell, to return a type indicating success or
failure.

\begin{listing}
\centering
\begin{cminted}{haskell}
throwTo    :: Exception e => ThreadId -> e -> IO ()
killThread :: ThreadId -> IO ()
\end{cminted}
\caption{Asynchronous exceptions in Haskell.}\label{lst:excsa_haskell}
\end{listing}

In addition to \emph{synchronous} exceptions, Haskell has
\emph{asynchronous} exceptions, shown in \Cref{lst:excsa_haskell},
which can be thrown to another thread.  These functions block until
the target thread is in an appropriate state to receive the exception.
Asynchronous exceptions can be caught with \verb|catch|, just like
synchronous exceptions thrown with \verb|throw|.

The Java \verb|Thread.stop| method is similar to \verb|killThread|,
but is considered a bad idea and deprecated, as it causes the target
thread to immediately release any locks it holds\cite{oracle2017}.
The preferred approach is the \verb|Thread.interrupt| method, which
will either throw an exception or set a flag, depending on what the
target thread is doing.  For example, if the target thread is blocked
inside a \verb|Thread.sleep| call, it will receive an
\verb|InterruptedException|.  Rust does not provide any way to tell a
thread to terminate.

\paragraph{Masking}
A thread has a masking state, which can be used to block exceptions
from other threads.  There are three masking states: (1)
\emph{unmasked}, in which a thread can have exceptions thrown to it;
(2) \emph{interruptible}, in which a thread can only have exceptions
thrown to it if it is blocked; and (3) \emph{uninterruptible}, in
which a thread cannot have exceptions thrown to it.

\begin{listing}
\centering
\begin{cminted}{haskell}
forkIOWithUnmask    :: ((forall a. IO a -> IO a) -> IO ()) -> IO ThreadId
forkOnWithUnmask    :: Int -> ((forall a. IO a -> IO a) -> IO ()) -> IO ThreadId

mask                :: ((forall a. IO a -> IO a) -> IO b) -> IO b
uninterruptibleMask :: ((forall a. IO a -> IO a) -> IO b) -> IO b
\end{cminted}
\caption{Masking exceptions in Haskell.}\label{lst:excm_haskell}
\end{listing}

There are two functions to set the masking state.  These each execute
a computation in the new state, and pass it a function to run a
subcomputation with the original masking state.  When a thread is
started, it inherits the masking state of its parent.  As the parent
may be masked, we can fork a thread with a function to run a
subcomputation with exceptions unmasked.  The API is shown in
\Cref{lst:excm_haskell}.

\paragraph{Software transactional memory}
STM can also use exceptions, as shown in \Cref{lst:excstm_haskell}.
If an exception propagates uncaught to the top of a transaction, that
transaction is aborted.  The \verb|orElse| function does not catch
exceptions.

\begin{listing}
\centering
\begin{cminted}{haskell}
throwSTM :: Exception e => e -> STM a
catchSTM :: Exception e => STM a -> (e -> STM a) -> STM a
\end{cminted}
\caption{STM exceptions in Haskell.}\label{lst:excstm_haskell}
\end{listing}

\section{Example Program}
\label{sec:concurrent_haskell-example}

\begin{listing}
\centering
\begin{cminted}{haskell}
import Control.Concurrent
import Control.Monad

main :: IO ()
main = forever $ do
  putStr "Enter a number of seconds: "
  s <- getLine                   -- 1
  forkIO (setReminder (read s))  -- 2

setReminder :: Int -> IO ()
setReminder s = do
  putStrLn ("Starting a " ++ show s ++ " second timer.")
  threadDelay (10^6 * s)        -- 3
  putStrLn "Time is up!\BEL"    -- 4
\end{cminted}
\caption[A simple alarm program.]{A simple alarm program.  Adapted from~\cite{marlow2013}.}\label{lst:ch_ex1}
\end{listing}
%$

\Cref{lst:ch_ex1} shows a simple program which prompts the user for a
number of seconds and prints a message, as well as ringing the
terminal bell, after that time.  This is a concurrent program.  The
user can keep entering new delays before old ones have elapsed.
Execution proceeds as follows:

\begin{enumerate}
\item Get a number of seconds from the user.
\item Fork a thread to execute the \verb|setReminder| function, and
  return to the prompt.
\item The new thread delays for the given number of seconds.
\item The new thread prints a message and sound the bell.
\end{enumerate}

We can extend this program to allow the user to type ``exit'' to quit.
\Cref{lst:ch_ex2} shows the new \verb|main| function.  This program is
similar to the original but, rather than using \verb|forever|, we use
a custom recursive function; we also only loop in the case where the
input is not ``exit.''

\begin{listing}
\centering
\begin{cminted}{haskell}
main :: IO ()
main = loop where
  loop = do
    putStr "Enter a number of seconds, or \"exit\": "
    s <- getLine
    if s == "exit"
      then pure ()
      else do
        forkIO (setReminder (read s))
        loop
\end{cminted}
\caption{A simple alarm program, with an exit instruction.}\label{lst:ch_ex2}
\end{listing}

This program now demonstrates an important property of Haskell
threading.  The user can quit even if there are reminder threads still
running.  All Haskell threads terminate when the main thread does,
regardless of what they are doing.  Haskell provides the simplest
behaviour, leaving it to libraries to implement higher-level behaviour
using these building blocks.

\paragraph{Shared state}
We can modify our program to only quit when every reminder is done.
To achieve this, we need to know if there are any reminders
outstanding.  One way to do this is to give every reminder thread an
\verb|MVar|, which we write to when done.  \Cref{lst:ch_ex3} shows the
new \verb|main| function.

\begin{listing}
\centering
\begin{cminted}{haskell}
main :: IO ()
main = loop [] where
  loop vars = do
    putStr "Enter a number of seconds, or \"exit\": "
    s <- getLine
    if s == "exit"
      then mapM_ readMVar vars
      else do
        var <- newEmptyMVar
        forkIO $ do
          setReminder (read s)
          putMVar var ()
        loop (var:vars)
\end{cminted}
\caption{A simple alarm program, which blocks until every reminder is done.}\label{lst:ch_ex3}
\end{listing}
%$

For each reminder, we create an empty \verb|MVar|.  A reminder thread
fills its \verb|MVar| when done.  On exit, each \verb|MVar| is read
from, which will block if the \verb|MVar| is still empty.

So now the main thread will block until every reminder is done,
however this approach is not satisfactory.  Our \verb|MVar| list gains
one element each time we set a reminder, so our program has linear
space usage.  We can instead use a shared counter, and wait for the
count to be zero before terminating.  \Cref{lst:ch_ex4} shows the new
\verb|main| function.

\begin{listing}
\centering
\begin{cminted}{haskell}
main :: IO ()
main = loop =<< newMVar 0 where
  loop var = do
    putStr "Enter a number of seconds, or \"exit\": "
    s <- getLine
    if s == "exit"
      then wait var
      else do
        modifyMVar_ var (+1)
        forkIO $ do
          setReminder (read s)
          modifyMVar_ var (-1)
        loop var
  wait var =
    c <- readMVar var
    if c == 0 then pure () else wait var
\end{cminted}
\caption{A simple alarm program, which blocks until every reminder is done.}\label{lst:ch_ex4}
\end{listing}
%$

So now, rather than have a constantly growing list, we just have a
single \verb|MVar|.  When a new reminder is created the value in the
\verb|MVar| is incremented.  When a reminder terminates the value in
the \verb|MVar| is decremented.  However, this program has two flaws.
Firstly, \verb|modifyMVar_| is not atomic: if two threads are updating
the counter at the same time, one may undo the other's effect.
Secondly, we wait for all reminder threads to be done by looping until
a condition holds, which is inefficient.

\paragraph{Software transactional memory}
We can solve the two problems with the \verb|MVar|-counter approach
using STM instead.  Transactions are atomic, so we can modify the
counter atomically.  When aborted, a transaction blocks until any
referenced variables are updated, which is more efficient than
repeatedly checking.  \Cref{lst:ch_ex5} shows the new \verb|main|
function.

\begin{listing}
\centering
\begin{cminted}{haskell}
main :: IO ()
main = loop =<< newTVarIO 0 where
  loop var = do
    putStr "Enter a number of seconds, or \"exit\": "
    s <- getLine
    if s == "exit"
      then wait var
      else do
        atomically (modifyTVar var (+1))
        forkIO $ do
          setReminder (read s)
          atomically (modifyTVar var (-1))
        loop var
  wait var = atomically $ do
    c <- readTVar var
    if c == 0 then pure () else retry
\end{cminted}
\caption{A simple alarm program, which blocks until every reminder is done.}\label{lst:ch_ex5}
\end{listing}

It may not be obvious why reading a \verb|TVar| and aborting the
transaction is more efficient than reading an \verb|MVar| and looping.
But consider the scheduling behaviour.  The \verb|TVar| approach will
block until another thread writes to it.  However, the \verb|MVar|
approach will not block at all.  So in the \verb|MVar| case, the
thread could be scheduled multiple times in a row, even though this is
a waste of time.

This is the final version of our program.

\vfill\pagebreak
\section{Summary}

Going forward, the reader should keep in mind:

\begin{itemize}
\item GHC uses a green threading model.  Multiple Haskell threads are
  multiplexed onto a smaller number of operating system threads.  Two
  Haskell threads can execute in parallel if they are mapped to
  different operating system
  threads~\sref{concurrent_haskell-threads}.

% talk about daemon threads in this chapter?
% \item So-called daemon threads do not prevent the termination of a
%   program: a program terminates when all non-daemon threads do.  In
%   GHC's threading model, all Haskell threads other than the main
%   thread are daemon thread~\sref{concurrent_haskell-threads}.

\item Haskell threads may explicitly yield control to another thread,
  or block themselves until some delay has
  elapsed~\sref{concurrent_haskell-threads}.

\item An \verb|IORef| is a mutable reference, used for communication
  between threads.  \verb|IORef| operations come in two kinds:
  synchronised and unsynchronised.  Depending on the memory model of
  the processor the program is running on, unsynchronised operations
  may appear to happen out-of-order~\sref{concurrent_haskell-mmodel}.

\item An \verb|MVar| is another kind of mutable reference, but only
  has synchronised operations.  An \verb|MVar| may be full or empty:
  attempting to write to a full \verb|MVar|, or attempting to read
  from an empty \verb|MVar|, blocks.  \verb|MVar|s are used to
  implement mutual exclusion~\sref{concurrent_haskell-mmodel}.

\item A \verb|TVar| is yet another kind of mutable reference, used to
  implement software transactional memory.  Unlike \verb|IORef| and
  \verb|MVar| operations, \verb|TVar| operations can be composed, and
  the whole executed atomically.  Transactions do not permit arbitrary
  effects, only effects on \verb|TVar|s~\sref{concurrent_haskell-stm}.

\item Haskell has exceptions.  Like Java, arbitrary exception types
  can be created.  When an exception is thrown, control jumps back to
  the nearest enclosing suitable exception handler.  If there is no
  such handler, the thread is
  terminated~\sref{concurrent_haskell-exc}.

\item So-called asynchronous exceptions can be thrown from one thread
  to another.  An asynchronous exception is raised in the target
  thread like a normal exception: control jumps back to a suitable
  exception handler, or kills the
  thread~\sref{concurrent_haskell-exc}.

\item A thread can prevent the delivery of asynchronous exceptions by
  changing its masking state.  There are three states: (1) unmasked,
  allowing asynchronous exceptions to be delivered; (2) masked
  interruptible, only allowing an asynchronous exception to be
  delivered when the thread is blocked; and (3) masked
  uninterruptible, not allowing asynchronous exceptions at all.
  Throwing an asynchronous exception to a thread not in a suitable
  state to receive it blocks~\sref{concurrent_haskell-exc}.
\end{itemize}

We assume familiarity with Concurrent Haskell throughout the rest of
the thesis.
