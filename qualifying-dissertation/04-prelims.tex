\chapter{Preliminary Results}
\label{sec:prelims}

% "describe research work you have already undertaken; report any
% results you have already obtained and discuss their significance."

\todo{Dump in Search Party paper when complete enough. Intro to
  \dejafu{} and Search Party and their significance.}

\section{\dejafu{}}
\label{sec:prelims-dejafu}

\dejafu{}\footnote{[\dejafu{} is] A martial art in which the user's
  limbs move in time as well as space, [\ldots{}] It is best described
  as ``the feeling that you have been kicked in the head this way
  before''. \attrib{Terry Pratchett, Thief of Time}} is a library for
SCT in Haskell. It provides a generalisation of the standard IO-using
concurrency API, allowing for non-IO implementations to be used for
testing purposes. Schedule bounding\cite{pbound} is used by the
default test runner, although other test runners can be written.

\begin{justspacing}
\paragraph{Example}

\begin{minted}{haskell}
main :: IO ()
main = do
  shared <- newMVar 0
  forkIO . void $ swapMVar shared 1
  forkIO . void $ swapMVar shared 2
  readMVar shared >>= print
\end{minted}

As we shall see in \sect{prelims-dejafu-testing}, this program can be
tested to produce traces showing the three possible results:

\begin{verbatim}
[pass] Never Deadlocks (checked: 23)
[pass] No Exceptions (checked: 23)
[fail] Consistent Result (checked: 1)
  0 S0-------
  2 S0----P2---S0---
  1 S0----P1---S0---
\end{verbatim}

Here each of the last three lines represents a possible execution of
the program: ``S'' indicates the start of execution of a thread, ``P''
indicates the pre-emption of the running thread by another, and each
dash represents one step of execution.
\end{justspacing}

The rest of the section is organised as follows.

\begin{itemize}
  \item \sect{prelims-dejafu-conc} presents the typeclass concurrency-abstraction,
    emphasising a few points where it departs from the usual
    concurrency model.

  \item \sect{prelims-dejafu-testing} introduces writing tests with \dejafu{}.

  \item \sect{prelims-dejafu-impl} explains how the library implements systematic
    concurrency testing.

  \item \sect{prelims-dejafu-example} presents two small examples of concurrent
    applications.

  \item \sect{prelims-dejafu-related} gives pointers to existing concurrency testing
    work in both Haskell and other programming languages.

  \item \sect{prelims-dejafu-conclusion} draws conclusions and suggest further work
    from what has been presented in this paper.
\end{itemize}

\subsection{The \dejafu{} Concurrency API}
\label{sec:prelims-dejafu-conc}

Readers already familiar with Haskell's concurrency primitives may
wish to just skim this subsection to see the syntactic differences in the
\dejafu{} variant.

\begin{departure}
  Departures from the semantics of the traditional concurrency
  abstraction are highlighted like this.
\end{departure}

If we remove the limitations, allowing non-blocking reads and multiple
writes, we get to Haskell's traditional concurrency abstraction in the
IO
monad. \dejafu{}\footnote{\url{https://github.com/barrucadu/dejafu}}
generalises a very large subset of that abstraction to work in
arbitrary members of a typeclass, named MonadConc.

To make use of the \dejafu{} library, we must first import the class:

\begin{minted}{haskell}
import Control.Monad.Conc.Class
\end{minted}

\subsubsection*{Threads}
\label{sec:prelims-dejafu-conc-threads}

Threads let a program do multiple things at once. Every program has at
least one thread, which starts where \texttt{main} does and runs until
the program terminates. A thread is the basic unit of concurrency, it
lets us pretend (with parallelism, it might even be true!) that we're
computing multiple things at once.

We can start a new thread with the \texttt{fork} function\footnote{To
  save on horizontal space, a \texttt{MonadConc m =>} has been dropped
  from the start of every type signature.}:

\begin{minted}{haskell}
fork :: m () -> m (ThreadId m)
\end{minted}

This starts evaluating its argument in a separate thread. It also
gives us back a (monad-specific) \texttt{ThreadId} value, which we can
use to kill the thread later on, if we want.

In a real machine, there are of course a number of processors and
cores. It may be that a particular application of concurrency is only
a net gain if every thread is operating on a separate core, so that
threads are not interrupting each other. The GHC runtime refers to the
number of Haskell threads that can run truly simultaneously as the
number of \textit{capabilities}. We can query this value, and fork
threads which are bound to a particular capability:

\begin{minted}{haskell}
getNumCapabilities :: m Int
forkOn :: Int -> m () -> m (ThreadId m)
\end{minted}

\texttt{forkOn} interprets the capability number modulo the value
returned by \texttt{getNumCapabilities}.

\begin{departure}
  \texttt{getNumCapabilities} is not required to return a true
  result. The testing instances return ``2'' despite executing
  everything in the same capability, to encourage more
  concurrency. The IO instance does return a true result.
\end{departure}

Sometimes we just want the special case of evaluating something in a
separate thread, for which we can use \texttt{spawn} (implemented in
terms of \texttt{fork}):

\begin{minted}{haskell}
spawn :: m a -> m (CVar m a)
\end{minted}

This returns a CVar (\textit{Concurrent Variable}), to which we can
apply \texttt{readCVar}, blocking until the computation is done and
the value is stored.


\subsubsection*{Mutable State}
\label{conc-crefs}

Threading by itself is not really enough. We need to be able to
\textit{communicate} between threads: we've already seen an instance
of this with the \texttt{spawn} function.

The simplest type of mutable shared state provided is the CRef
(\textit{Concurrent Reference}). CRefs are shared variables which can
be written to and read from by any thread which has a reference:

\begin{minted}{haskell}
newCRef    :: a -> m (CRef m a)
readCRef   :: CRef m a -> m a
modifyCRef :: CRef m a -> (a -> (a, b)) -> m b
writeCRef  :: CRef m a -> a -> m ()
\end{minted}

\begin{departure}
  IORef actions be re-ordered\cite{ioref}, but this is not the case
  for CRef actions. \texttt{modifyCRef} corresponds to
  \texttt{atomicModifyIORef}, and \texttt{writeCRef} corresponds to
  \texttt{atomicWriteIORef}.
\end{departure}

As \textit{any} thread can write at \textit{any} time, then we risk
threads overwriting each other's work! At least \texttt{modifyCRef} is
atomic: no thread can update it between the value being read and the
new value being stored, as could happen if \texttt{readCRef} and
\texttt{writeCRef} were composed. Even so, CRefs quickly fall down if
we want to do anything complicated. We need something more robust.

\subsubsection*{Mutual Exclusion}
\label{sec:prelims-dejafu-conc-cvars}

A CVar is a shared variable under \textit{mutual exclusion} It has two
possible states: \textit{full} or \textit{empty}. Writing to a full
CVar blocks until it is empty, and reading or taking from an empty
CVar blocks until it is full. There are also non-blocking functions
which return an indication of success:

\begin{minted}{haskell}
putCVar     :: CVar m a -> a -> m ()
tryPutCVar  :: CVar m a -> a -> m Bool
readCVar    :: CVar m a -> m a
takeCVar    :: CVar m a -> m a
tryTakeCVar :: CVar m a -> m (Maybe a)
\end{minted}

Unfortunately, the mutual exclusion behaviour of CVars means that
computations can become deadlocked. For example, deadlock occurs if
every thread tries to take from the same CVar. The GHC runtime can
detect this (and will complain if it does), and so can \dejafu{} in a
more informative way, as we shall see in \sect{prelims-dejafu-testing}.

\subsubsection*{Software Transactional Memory}
\label{sec:prelims-dejafu-conc-stm}

CVars are nice, until we need more than one, and find they need to be
kept synchronised. As we can only claim \textit{one} CVar atomically,
it seems we need to introduce a CVar to control access to CVars! This
is unwieldy and prone to bugs.

\textit{Software transactional memory} (STM) is the solution. STM uses
CTVars, or \textit{Concurrent Transactional Variables}, and is based
upon the idea of atomic \textit{transactions}. An STM transaction
consists of one or more operations over a collection of CTVars, and
the programmer can bail out of a transaction part-way through if they
want. If the transaction fails, \textit{none of its effects take
  place}, and the thread blocks until the transaction can
succeed. This means we need to limit the possible actions in an STM
transaction, so we have another typeclass:

\begin{minted}{haskell}
import Control.Monad.STM.Class
\end{minted}

CTVars always contain a value, as shown in the types of the functions:

\begin{minted}{haskell}
newCTVar   :: MonadSTM s => a -> stm (CTVar s a)
readCTVar  :: MonadSTM s => CTVar s a -> s a
writeCTVar :: MonadSTM s => CTVar s a -> a -> s ()
\end{minted}

If we read a CTVar and don't like the value it has, the transaction
can be aborted, and the thread will block until any of the referenced
CTVars have been mutated:

\begin{minted}{haskell}
retry :: MonadSTM s => s a
check :: MonadSTM s => Bool -> s ()
\end{minted}

We can also try executing a transaction, and do something else if it
fails:

\begin{minted}{haskell}
orElse :: MonadSTM s => s a -> s a -> s a
\end{minted}

The nice thing about STM transactions is that they
\textit{compose}. We can take small STM transactions and build bigger
transactions from them, and the whole is still executed
atomically. This means we can do complex state operations involving
multiple shared variables without worrying!

We have emphasised that STM transactions are atomic. Here is the
function which executes a transaction:

\begin{minted}{haskell}
atomically :: STMLike m a -> m a
\end{minted}

\begin{departure}
  Every MonadConc has an associated MonadSTM, whereas there is just
  one STM normally. This is so that STM transactions can be tested
  without needing to bring IO into the test runner. The IO MonadConc
  instance uses STM as its MonadSTM.
\end{departure}

For example, if we have a collection of worker threads which can
either produce a result or fail, we might want to block until either
\textit{one} completes successfully and then kill the other threads,
or until \textit{all} fail. We can implement this using CTMVars, an
analogue of CVars built from CTVars:

\begin{minted}{haskell}
awaitResult :: MonadConc m => [(ThreadId m, CTMVar (STMLike m) (Maybe a))]
  -> m (Maybe a)
awaitResult workers = do
  out <- atomically $ do
    progress <- mapM (tryReadCTMVar . snd) workers
    let finished = catMaybes progress
    case catMaybes finished of
      (x:_) -> return $ Just x
      [] -> check (length finished < length workers)
            >> return Nothing
  mapM_ (killThread . fst) workers
  return out
\end{minted}

We can of course test STM transactions individually. The result may be
a success (along with the value returned), a failure due to a
\texttt{retry}, or a failure due to an uncaught exception:

\begin{minted}{haskell}
import Test.DejaFu.STM
runTransaction :: (forall t. STMLike t (ST t) (STRef t) a) -> Result a
\end{minted}

The type is a bit scary, but if we program against the MonadSTM
interface, things will just work.

\subsubsection*{Exceptions}
\label{sec:prelims-dejafu-conc-excs}

Exceptions are a way to bail out of a computation early. Whether
they're a good solution to that problem is a question of style, but
they can be used to quickly jump to error handling code when
necessary. The basic functions for dealing with exceptions are:

\begin{minted}{haskell}
catch :: Exception e => m a -> (e -> m a) -> m a
throw :: Exception e => e -> m a
\end{minted}

Where \texttt{throw} causes the computation to jump back to the
nearest enclosing \texttt{catch} capable of handling the particular
exception. As exceptions belong to a typeclass, rather than being a
concrete type, different \texttt{catch} functions can be nested, to
handle different types of exceptions.

\begin{departure}
  The IO \texttt{catch} function can catch exceptions from pure
  code. This is not true in general for MonadConc instances,
  unfortunately meaning that some things which work normally may not
  work in testing. This is a small cost, however, as exceptions from
  pure code are things like pattern match failures and evaluating
  \texttt{undefined}, which are arguably bugs.
\end{departure}

Exceptions can be used to kill a thread:

\begin{minted}{haskell}
throwTo    :: Exception e => ThreadId m -> e -> m ()
killThread :: ThreadId m -> m ()
\end{minted}

These functions block until the target thread is in an appropriate
state to receive the exception.

What if we don't want our threads to be subject to destruction in this
way? A thread also has a \textit{masking state}, which can be used to
block exceptions from other threads. There are three masking states:
\textit{unmasked}, in which a thread can have exceptions thrown to it;
\textit{interruptible}, in which a thread can only have exceptions
thrown to it if it is blocked; and \textit{uninterruptible}, in which
a thread cannot have exceptions thrown to it. When a thread is
started, it inherits the masking state of its parent, and the
\texttt{forkWithUnmask} function forks a thread and passes it a
function which can be used to execute a subcomputation in the unmasked
state. We can also execute a subcomputation with a new masking state:

\begin{minted}{haskell}
mask                :: ((forall a. m a -> m a) -> m b) -> m b
uninterruptibleMask :: ((forall a. m a -> m a) -> m b) -> m b
forkWithUnmask      :: ((forall a. m a -> m a) -> m ()) -> m (ThreadId m)
\end{minted}

STM can also do exceptions, with its \texttt{throwSTM} and
\texttt{catchSTM} functions. If an STM exception propagates uncaught
to the top of a transaction, that transaction is aborted.

\subsection{Testing using \dejafu{}}
\label{sec:prelims-dejafu-testing}

Testing with \dejafu{} consists in writing a unit test-like concurrent
computation to test, and some predicates over the return value and
traces produced. Predicates may be lazy, and so not need to examine
the entire output before determining whether the test has passed or
failed:

\begin{minted}{haskell}
type Predicate a = [(Either Failure a, Trace)] -> Result a

runTest :: Eq a => Predicate a -> (forall t. Conc t a) a
\end{minted}

Helper functions lift predicates over a single result to predicates
over the collection:

\begin{minted}{haskell}
alwaysTrue    :: (Either Failure a -> Bool) -> Predicate a
somewhereTrue :: (Either Failure a -> Bool) -> Predicate a
\end{minted}

There are also variants which take predicates of two arguments for
checking properties over the entire collection as a whole, for
example:

\begin{minted}{haskell}
alwaysSame :: Eq a => Predicate a
alwaysSame = alwaysTrue2 (==)

alwaysTrue2    :: (Either Failure a -> Either Failure a -> Bool) -> Predicate a
somewhereTrue2 :: (Either Failure a -> Either Failure a -> Bool) -> Predicate a
\end{minted}

The functions \texttt{alwaysTrue2} and \texttt{somewhereTrue2} only
check the predicate between values adjacent in the result list, the
order of which depends on the scheduling algorithm used, and so should
only be used for properties which are symmetric and transitive. There
is also a collection of standard predicates, for doing things like
checking for the existence of deadlock.

Let's see what we get from testing the example from the start of this
paper. We'll have it return the value, rather than print it, though:

\begin{minted}{haskell}
import Control.Concurrent.CVar (swapCVar)
import Control.Monad (void)
import Control.Monad.Conc.Class

bad :: (Functor m, MonadConc m) => m Int
bad = do
  shared <- newCVar 0
  fork . void $ swapCVar shared 1
  fork . void $ swapCVar shared 2
  readCVar shared
\end{minted}

Firstly let's put it through \texttt{autocheck}:

\begin{verbatim}
> import Test.DejaFu
> autocheck bad
[pass] Never Deadlocks (checked: 23)
[pass] No Exceptions (checked: 23)
[fail] Consistent Result (checked: 1)
  0 S0-------
  2 S0----P2---S0---
  1 S0----P1---S0---
False
\end{verbatim}

\dejafu{} reports three distinct failures! Two failures are distinct
if they have different results, or the same result but one trace is
not a simplification of another. For each failure, the result is
shown, along with the trace that led to it. ``Sx'' means that thread
``x'' started execution; ``Px'' means that thread ``x'' pre-empted the
running thread; and the number of dashes indicates how many steps each
thread ran for. So this output means that we get a ``0'' if there is
no pre-emption, a ``1'' if thread 1 pre-empts the initial thread
before the read, and a ``2'' if thread 2 pre-empts the initial thread
before the read.

This output is nice for automated test suites, but perhaps not so
friendly for interactive debugging. There are functions to run tests
and return a more detailed result:

\begin{verbatim}
> runTest alwaysSame bad
Result {_pass = False, _casesChecked = 1
       , _casesTotal = 23, _failures = [...]}
\end{verbatim}

The Result value tells us testing failed after looking at 1 case,
there are 23 cases in total, and there is a simplified list of
failures. These are quite long, so here is the second only:

\begin{minted}{haskell}
( Right 2
, [ (Start 0,[],New 1)
  , (Continue,[],Put 1 [])
  , (Continue,[],Fork 1)
  , (Continue,[SwitchTo 1],Fork 2)
  , (SwitchTo 2,[Continue,SwitchTo 1],Take 1 [])
  , (Continue,[SwitchTo 0,SwitchTo 1],Put 1 [])
  , (Continue,[SwitchTo 0,SwitchTo 1],Stop)
  , (Start 0,[Start 1],Read 1)
  , (Continue,[SwitchTo 1],Lift)
  , (Continue,[SwitchTo 1],Stop)])
\end{minted}

We have the result returned, and a log of what decision the scheduler
made at each step, what alternative decisions it \textit{could} have
made, and what the thread did. Each thread and CVar (and CRef/CTVar)
has its own unique identifier. In particular, we can see that when
thread 2 pre-empted thread 0, it modified CVar 1, and the final result
was determined by CVar 1 (well, we don't actually see that bit, but we
see that CVar 1 was read just before the main thread terminated), this
should suggest to us that maybe CVar 1 is the culprit, and lead us to
look more closely at that rough area of the program. It may seem
difficult to keep track of which thread is which, but studies have
found\cite{empirical} that many errors are exposed with as few as two
threads, giving us encouragement to write small test cases;
alternatively, there could be provided an optional mechanism to assign
names to threads.

\subsubsection*{Testing Aids}
\label{sec:prelims-dejafu-testing-aids}

Some other functions generically defined for the typeclass only alter
the running of the code during testing. They are provided to make it
easier to write good tests.

Firstly, there is \texttt{\_concNoTest}, it indicates that a
subcomputation already has its own tests, and so it should not be
tested again \textit{here}. Specifically, the test runner executes the
argument of \texttt{\_concNoTest} atomically. This allows tests to
compose without repeating work:

\begin{minted}{haskell}
big :: MonadConc m => m Int
big = do
  a <- _concNoTest little1
  b <- _concNoTest little2
  combine a b
\end{minted}

If ``little1'' and ``little2'' already have their own tests, and have
been verified to work, there is no need to test them again when
testing ``big''.

Secondly, there are cases where the main thread may be blocked on some
CVar or CTVar, to which no other thread has a reference. This should
cause immediate failure with deadlock as the reason. By default
\dejafu{} cannot detect deadlocks of this kind. However, the user has
the option to provide extra information, indicating which shared
variables a thread knows about:

\begin{minted}{haskell}
bad :: MonadConc m Int
bad = do
  _concAllKnown
  a <- newEmptyCVar
  b <- newEmptyCVar
  fork $ do
    _concKnowsAbout (Left a)
    _concAllKnown
    let loop = takeCVar a >> loop in loop
  fork $ do
    _concKnowsAbout (Left a)
    _concAllKnown
    let loop = putCVar a 1 >> loop in loop
  takeCVar b
\end{minted}

The main thread is blocked on ``b'', which neither of the other two
threads has a reference to. By adding the annotations, this can be
detected and reported. There are three annotations:
\texttt{\_concKnowsAbout}, which records that the current thread has a
reference to a CVar or CTVar; \texttt{\_concForgets}, which records
that the current thread will never touch the referenced CVar or CTVar
again; and \texttt{\_concAllKnown}, which indicates that all CVars or
CTVars which were passed in to the thread have been recorded. If every
thread is in a known state, then detection of non-global deadlock is
enabled. In the example above, without this, the computation would
never terminate, as the two forked threads will run forever, even
though the main thread can never progress.

Note that misuse of these aids can lead to invalid test results. In
particular, \texttt{\_concNoTest} should only be used for actions
which involve no shared variables from a larger scope. If two threads
with a reference to the same shared variable are executed under
\texttt{\_concNoTest}, then the test runner will not consider possible
interleavings of those threads.

\subsubsection*{IO}
\label{sec:prelims-dejafu-testing-io}

By itself, MonadConc cannot do IO. However, by adding in a MonadIO
context and applying \texttt{liftIO} as appropriate, concurrency
can be separated from other IO, allowing testing.

However, once IO is involved, the test runner loses control of what's
going on. If a thread, during some IO, blocks on the action of another
thread, this cannot be detected, and deadlock may arise. Furthermore,
it is assumed for testing that the only source of nondeterminism is
the scheduler (see \sect{prelims-dejafu-impl}). Any IO that is done should be
deterministic enough to not invalidate test results, although this is
good practice in any sort of testing. Finally, the test runner cannot
pre-empt within a \texttt{liftIO} block, they should be as small as
possible to avoid the risk of obscuring bugs.

\subsection{Implementation}
\label{sec:prelims-dejafu-impl}

Readers who just want to use the \dejafu{} library can skip over this
subsection and go straight to the example applications in \sect{prelims-dejafu-example}.

\subsubsection*{Primitive Actions and Threading}
\label{impl-prims}

The Conc and ConcIO monads represent threads as continuations over
primitive actions, with the entire computation actually happening in a
single Haskell thread. The primitives actions are as follows (in
abbreviated form):

\begin{minted}{haskell}
data Action ... =
    AFork     thread_action action
  | AMyTId    (thread_id -> action)
  | APut      cvar new_value action
  | ATryPut   cvar new_value (Bool -> action)
  | AGet      cvar (value -> action)
  | ATake     cvar (value -> action)
  | ATryTake  cvar (Maybe value -> action)
  | AReadRef  cref (value -> action)
  | AModRef   cref function (result -> action)
  | AAtom     stm_action (result -> action)
  | ANew      action
  | ANewRef   action
  | ALift     (underlying_monad action)
  | AThrow    exc
  | AThrowTo  thread_id exc action
  | ACatching handler action (result -> action)
  | AMasking  mask_state action (result -> action)
  | AStop
\end{minted}

There are also a few other primitives omitted here introduced as a
side-effect of evaluating other primitives (for example, resetting the
masking state). Execution happens in the context of an underlying
monad, which implements mutable variables. For \texttt{Conc t} this is
\texttt{ST t}, hence the type parameter. For \texttt{ConcIO t} it is
\texttt{IO}, the parameter is retained to keep types similar.

Threads are stored in a map, from thread IDs to a record of the
current state:

\begin{minted}{haskell}
data Thread ... = Thread
  { _continuation :: Action ...
  , _blocking     :: Maybe BlockedOn
  , _handlers     :: [Handler ...]
  , _masking      :: MaskingState
  }
\end{minted}

Evaluation is defined as repeating a single-step function until the
main thread terminates, or deadlock is detected.

\subsubsection*{Shared State and Blocking}
\label{sec:prelims-dejafu-impl-state}

CRefs and CVars are both implemented in terms of the reference type of
the underlying monad, as a pair (id, value), where CVars have a maybe
value.

\begin{minted}{haskell}
data BlockedOn =
    OnCVarFull CVarId
  | OnCVarEmpty CVarId
  | OnCTVar [CTVarId]
  | OnMask ThreadId deriving Eq
\end{minted}

When a CVar is accessed, the running thread is blocked if the CVar is
in an inappropriate state. Otherwise the action of the thread is
replaced with the relevant continuation. If the CVar has been mutated,
then all threads blocked on reading that CVar (if it was put in to) or
writing (if it was taken from) are unblocked. This unblocking
behaviour is slightly different to MVars, where there the order of
awakening is FIFO.

STM is implemented in terms of its own primitive actions. CTVars are
implemented in the same way as CRefs. Executing an STM transaction
returns a result (or indication of failure), a list of CTVars written
to (if success) or read from (if failure), and an action in the
underlying monad to undo the effects of the transaction:

\begin{minted}{haskell}
data STMAction ... =
    ACatch  action handler (result -> action)
  | ARead   ctvar (value -> action)
  | AWrite  ctvar new_value action
  | AOrElse action action (result -> action)
  | ANew    action
  | ALift   (underlying_monad action)
  | AThrow  SomeException
  | ARetry
  | AStop
\end{minted}

Blocking is implemented by checking if a transaction terminated due to
an \texttt{ARetry} action, at which point the thread is blocked, and
unblocked by a future \texttt{AAtom} action which modifies at least
one of the CTVars referenced in the failing transaction.

\subsubsection*{Exceptions}
\label{sec:prelims-dejafu-impl-excs}

A thread has a stack of exception handlers. Upon entering a
\texttt{catch}, the handler is pushed to the stack, and a primitive
action to pop it is inserted at the end of the enclosed action. A
handler, when invoked, replaces the action of the thread entirely,
this works by jumping to the continuation of the \texttt{catch} after
the programmer-supplied function terminates:

\begin{minted}{haskell}
data Handler ... = forall e. Exception e => Handler (e -> Action ...)
\end{minted}

Upon evaluating a \texttt{throw}, the exception handler stack is
popped until a handler capable of handling the exception is
reached. The action of the thread is then replaced with the handler,
and the new stack is stored. If no handler is found, the thread is
killed. If this is the main thread, the entire computation terminates
with an error.

When a mask is entered, a primitive action to restore the masking
state is added on to the end of the subcomputation, similarly to how
the \texttt{catch} function works.

As an STM transaction is executed all in one go, this greatly
simplifies the implementation of exceptions. An STM catch action is
implemented by simply executing the entire subcomputation and pattern
matching on the return value: if it is a success, the value is
returned; if it is an exception of the appropriate type, it is passed
to the handler; and if it is a different exception, it is propagated
upwards.

\subsubsection*{Detecting Deadlock}
\label{sec:prelims-dejafu-impl-tests}

Deadlock detection is implemented in GHC as part of garbage
collection: if a thread is blocked on a variable which no running
thread has a reference to, that thread is deadlocked. Unfortunately,
the garbage collector is out of the reach of \dejafu{} (and even if it
wasn't, would require everything to be in IO), and so by default the
only deadlock detection is global: where every thread is blocked
simultaneously.

Deadlock where the main thread is blocked on a shared variable no
other thread has a reference to is optionally implemented with special
\texttt{\_conc} functions, as seen in \sect{prelims-dejafu-testing}. These record for
each thread which shared variables are known about, allowing largely
the same approach as the GC one if the state of every thread is fully
known. The only downside is that if these functions are incorrectly
used, there may be false results of testing.

\subsubsection*{Schedule Bounding}
\label{sec:prelims-dejafu-impl-bound}

Testing in \dejafu{} is, by default, implemented using pre-emption
bounding with a bound of two, which is itself a specialisation of the
explicit support for schedule bounding. Enough of the internals are
exposed such that other SCT runners could be implemented.

An execution is parameterised with a deterministic scheduler which may
have some state, and the execution returns the result, an execution
trace, and the final scheduler state. Using the scheduler state, we
can implement a very simple scheduler which takes some list of initial
decisions to make (a schedule prefix), and which makes non-pre-emptive
decisions after that point. Schedule bounding is implemented in terms
of generating new schedules from a schedule prefix and suffix.

Specifically, given a schedule suffix, there are functions to generate
\textit{siblings} and \textit{offspring}. A sibling is a new partial
prefix which, when appended to any prefix at all, does not result in a
prefix in a different bounding level. An offspring is a new partial
prefix which, when appended to any prefix at all, results in a prefix
in the next bounding level up. In the case of pre-emption bounding,
siblings are partial prefixes with no pre-emptions, and offspring are
partial prefixes with one pre-emption, so producing a prefix with
$n+1$ pre-emptions when appended to the original prefix.

\begin{justspacing}
\paragraph{Example}

\begin{minted}{haskell}
prefix = [Start 0]
suffix = [(Continue, [], Fork 1)
         ,(Continue, [SwitchTo 1], Stop)]
\end{minted}

Given this prefix and suffix, under pre-emption bounding there are no
siblings, as the only available alternative choice would introduce a
pre-emption. There is one offspring, by making the alternative
decision at step 2 of the suffix:

\begin{minted}{haskell}
siblings suffix == []
offspring suffix == [[Continue, SwitchTo 1]]
\end{minted}

This offspring would not be generated, however, as pre-emptions are
only introduced around actions where it may effect the final result,
such as access to a CVar. \hfill $\qed$
\end{justspacing}

This splitting into prefixes and suffixes makes it easy to prevent
duplicate schedules. The schedule bounding runner stops generating
offspring when the bound is reached, and explores schedules in a
mostly breadth-first fashion. A negative bound can be passed in to
explore all schedules, although this may take some time.

Also implemented is a delay-bounding scheduler. A \textit{delay} is a
deviation from an otherwise deterministic scheduler, and so
delay-bounding has the advantage that the number of schedules grows
more slowly than pre-emption bounding, as there is exactly one
schedule with a delay count of 0, but potentially many with a
pre-emption count of 0. The default testing mechanisms use pre-emption
bounding because the guarantees that delay-bounding gives are
influenced by the choice of scheduler, whereas pre-emption bounding
gives a global property of all schedules, although both methods tend
to perform about the same in terms of bug-finding
ability\cite{empirical}.

\subsection{Examples}
\label{sec:prelims-dejafu-example}

Two very different examples are discussed. The first is a variation of
an example in \textit{Parallel and Concurrent Programming in
  Haskell}\cite{parconc} of a concurrent message logger, into which a
bug has intentionally been introduced. The entire program is
presented, as it is very small. The second is a bug that arose,
unintentionally, in the implementation of a library for performing
search problems in parallel, where an incorrect use of CTMVars allowed
a user of the library to obtain an incomplete result.

\subsubsection*{Message Logger}
\label{example-logger}

We want a concurrent message logger with the following properties:

\begin{itemize}
  \item The logger can be sent a message, or it can be told to stop;
    when told to stop, all messages sent before that point are
    returned to the thread which stopped it.

  \item Messages from the same thread should be in order, but messages
    from different threads may be in any order.
\end{itemize}

Firstly, we shall define the types we're going to use:

\begin{minted}{haskell}
data Logger m   = Logger (CVar m LogCommand) (CVar m [String])
data LogCommand = Message String | Stop

initLogger :: MonadConc m => m (Logger m)
initLogger = do
  cmd <- newEmptyCVar
  log <- newCVar []
  let l = Logger cmd log
  fork $ logger l
  return l
\end{minted}
%$

Now we need to be able to send a message to the logger. As CVars are
being used, these functions will block if there is already a command
there, we don't need to worry about thread overwriting each other's
commands.

\begin{minted}{haskell}
logMsg :: MonadConc m => Logger m -> String -> m ()
logMsg (Logger cmd _) = putCVar cmd . Message

logStop :: MonadConc m => Logger m -> m [String]
logStop (Logger cmd log) = do
  putCVar cmd Stop
  readCVar log
\end{minted}

Finally, we have the main loop of the logger. It blocks on taking a
command and then, if it's a new message, appends the message to the
list and loops, otherwise it terminates.

\begin{minted}{haskell}
logger :: MonadConc m => Logger m -> m ()
logger (Logger cmd log) = loop where
  loop = do
    command <- takeCVar cmd
    case command of
      Message str -> do
        strs <- takeCVar log
        putCVar log $ strs ++ [str]
        loop
      Stop -> return ()
\end{minted}
%$

One immediate thing to note is that if at least two threads attempt to
communicate with the logger after it has been stopped, one will block
indefinitely. If we assume one supervising process which orchestrates
the concurrency (for example, a managing thread which starts a logger
and a collection of worker threads, which report their status to the
log), then this isn't a problem as the program can be structured to
avoid this.

The actual bug is less obvious, so let's write a simple test case and
see what \texttt{autocheck} does for us:

\begin{minted}{haskell}
test :: MonadConc m => m [(ThreadId m, String)]
test = do
  l <- initLogger
  j1 <- spawn (logMsg l "a" >> logMsg l "b")
  j2 <- spawn (logMsg l "c" >> logMsg l "d")
  readCVar j1; readCVar j2
  logStop l
\end{minted}

Here we start a logger, fork off two threads which each write two
messages to the log, wait for them to terminate, and stop the
logger. We should always see 4 log entries, with ``a'' before ``b'',
``c'' before ``d'', but all other orderings.

Running with \texttt{autocheck}, we see\footnote{Traces have been
  broken into multiple lines here, but the tool does not do any output
  wrapping by itself.} the following:

\begin{verbatim}
> autocheck test
[pass] Never Deadlocks (checked: 104626)
[pass] No Exceptions (checked: 104626)
[fail] Consistent Result (checked: 5)
  ["a","b","c"] S0---------S2-----S3---S1----S2--
    -S1----S3---S1----S3---S1-P0------
  ["a","b","c","d"] S0---------S2-----S1----S2---
    S1----S3-----S1----S3---S1----S0------
  ["a","b","c"] S0---------S2-----S1----S2---S1--
    --S3-----S1----S3---S0---S1-P0----
  ["a",c","b"] S0---------S2-----S1----S3-----S2-
    S1----S2---S1----S3---S1-P0------
  ["a","c","b","d"] S0---------S2-----S1----S3---
    --S1----S2---S1----S3---S1----S0------
  ...
False
\end{verbatim}

Well, we found a bug: sometimes the last message gets missed. Also,
the cases where the last message is dropped all appear to end with a
pre-emption of thread 1 (the logger thread) by thread 0 (the initial
thread). We can restrict the results by checking a different
condition:

\begin{verbatim}
> dejafu test
  ( "4 Values"
  , alwaysTrue $ \(Right xs) -> length xs == 4)
[fail] 4 Values (checked: 16)
  ["a","b","c"] S0---------S2-----S3---S1----S2--
    -S1----S3---S1----S3---S1-P0------
  ["a","b","c"] S0---------S2-----S1----S2---S1--
    --S3-----S1----S3---S0---S1-P0----
  ["a","c","b"] S0---------S2-----S1----S3-----S2
    -S1----S2---S1----S3---S1-P0------
  ["a","c","d"] S0---------S2-----S1----S3-----S1
    ----S3---S2-S1----S2---S1-P0------
  ["a","c","b"] S0---------S2-----S1----S3-----S1
    ----S2---S1----S3---S0---S1-P0----
  ...
False
\end{verbatim}

We see that the pattern continues. Upon a closer inspection of
\texttt{logger}, we can see that if it is pre-empted between the
\texttt{takeCVar cmd} and the \texttt{takeCVar log}, a stop command
can be written without blocking, and an incomplete log returned. One
solution to this would be to replace the first \texttt{takeCVar} with
a \texttt{readCVar}, and only empty the CVar when the processing of
the command is complete.

\subsubsection*{Parallel Search}
\label{sec:prelims-dejafu-example-searchparty}

A library called
\textit{search-party}\footnote{\url{https://github.com/barrucadu/search-party}}
has been developed, for speculative parallelism in generate-and-test
search problems. It is motivated by the consideration that: if
multiple acceptable solutions exist, it doesn't matter which one is
returned, as long as one is guaranteed to be returned. Initially, only
single results could be returned, but support for returning all
results was later added, incorrectly, introducing a bug.

The key piece of code causing the problem was this part of the worker
loop:

\begin{minted}{haskell}
case maybea of
  Just a -> do
    atomically $ do
      val <- tryTakeCTMVar res
      case val of
        Just (Just as) -> putCTMVar res $ Just (a:as)
        _ -> putCTMVar res $ Just [a]
    unless shortcircuit $
      process remaining res
  Nothing -> process remaining res
\end{minted}

Here ``maybea'' is a value indicating whether the particular
computation just evaluated was successful. The intended behaviour is
that, when gathering all results, if a computation is successful it is
added to the list in the ``res'' CTMVar, and then in any case
processing continues. This CTMVar is exposed indirectly to the user of
the library, it is blocked upon when the final result of the search is
requested.

There are some small tests in search-party, verifying that deadlocks
and exceptions don't arise, and that results are as expected. Upon
introducing this new functionality, tests began to fail with differing
result lists returned for different schedules:

\begin{minted}{haskell}
checkResultLists :: Eq a => Predicate [a]
checkResultLists = alwaysTrue2 check
  where
  check (Right as) (Right bs) =
    as `elem` permutations bs
  check a b = a == b
\end{minted}

Given this predicate, we can very clearly see the problem:

\begin{verbatim}
> dejafu (runFind $ [0..2] @! const True)
         ("Result Lists", checkResultLists)
[fail] Result Lists (checked: 46)
  Just [2,1] S0----S1-----S2-P3-----------S0----
  Just [0,2,1] S0----S1-----S2-P3-----------S2---
    ---S0----
  Just [2,1] S0----S1-----S2--P3-----------S0----
  Just [0,2,1] S0----S1-----S2--P3-----------S2--
    ---S0----
  Just [2,1] S0----S1-----S2---P3-----------S0----
  ...
False
\end{verbatim}

In this case, fixing the failure did not require any interactive
debugging, as only one place had been modified in introducing the new
functionality, and re-reading the code with the possibility of error
in mind led immediately to noticing the bug. However, the ability to
produce a test case which reliably reproduces the problem allows
confidence that it will be caught if it is reintroduced in a future
version of the library.

Specifically, there was no indication that a list-producing
computation had finished. As results were written directly to the
CTMVar, partial result lists could be read depending on how the worker
threads and the main thread were interleaved.

\subsection{Related Work}
\label{sec:prelims-dejafu-related}

Pre-emption bounding testing tools exist for both C\cite{maple} and
Java\footnote{LazyLocks (Paul Thomson), to appear.} at least. SCT in
Java is particularly nice, as the bytecode can be instrumented to
support SCT at runtime, by the test runner. This frees the programmer
from the need to structure their code in such a way to support SCT,
they can just program as they have always done. This also allows
legacy concurrent applications to be tested easily.

PULSE\cite{pulse} is a concurrency testing tool for Erlang, where
processes are synchronised by communicating with a scheduler process,
and QuickCheck is used for schedule generation.  PULSE supports
automatic code instrumented to support this style of testing. As
Erlang processes may be distributed, pre-emption bounding may not be
suitable, as it assumes everything is executing on a single
processor. Whilst there has been work on Erlang-style concurrency for
Haskell\cite{cloudhaskell}, it is still relatively unpopular; in this
case a PULSE-style approach may be better there.

Whilst the MonadConc typeclass was structured to be similar to the
standard concurrency primitives, the inspiration for this approach,
and the basic idea behind how to do SCT in Haskell, was provided by a
blog post\cite{typeclass}. However, both the family of primitives and
the approach to testing have been significantly advanced.

\subsection{Conclusions \& Further Work}
\label{sec:prelims-dejafu-conclusion}

Although a common joke amongst Haskell programmers is that ``if it
compiles, it works'', this is demonstrably not the case. A number of
profiling and debugging tools exist, typically requiring special
runtime support. Concurrency is a particularly difficult area to get
right, as everyone who has had to move outside the realm of guaranteed
determinism will know. Yet there are no debugging tools for concurrent
Haskell programs (ThreadScope\cite{threadscope} is a profiling tool,
and merely gathers information on sample executions). This paper
contributes such a tool, at the cost of a programmer having to use a
generalisation of the familiar concurrency abstraction.

Is this cost too high? Programmers are notoriously unwilling to
restructure their code to allow for easier analysis or testing, unless
the current situation is truly unbearable. It is generally regarded in
the Haskell community as good practice to write IO-using functions as
thin wrappers around calls to pure code, which hopefully will reduce
the amount of change needed. The MonadConc and MonadSTM interfaces
have been kept intentionally very similar to the IO and STM
interfaces, typically all that a programmer needs to do will be to
change some imports, some names, and a few type signatures.

We implemented a library for fast parallel search on top of this
abstraction, and some shortcomings were identified and rectified. In
particular, there was originally no CRef type, as IORefs operations
can potentially be re-ordered\cite{ioref}. However, IORefs with
non-reorderable updates turned out to be exactly the abstraction
needed for search-party's work stealing scheduler, and so it was
added.

Naturally, there is still work to be done:

\begin{itemize}
  \item Swapping out the regular concurrency primitives for the
    MonadConc primitives could be done at compile- or link-time, rather
    than at the level of code. This would allow testing of legacy code,
    and also free the programmer from needing to modify their code,
    however it would require recompiling all dependencies with this
    functionality enabled (as is currently the case when building
    something with profiling enabled).

  \item It is impossible in the current implementation to include
    functions like \texttt{threadDelay}, as testing assumes that any
    nondeterminism is due to the scheduler, but causing a thread to
    sleep is a notoriously nondeterministic operation, with the actual
    amount of time slept depending partly on the operating system's
    scheduler, which remains out of reach.

  \item If a thread enters an infinite loop, or something similar, in
    one primitive action call, the entire test runner will lock up,
    even if that would not happen when executing normally. This is
    because the test runner cannot do things on a granularity smaller
    than one primitive action.

  \item Whilst some work is done to not explore uninteresting
    schedules, it is very naive. Dynamic partial-order reduction
    (DPOR)\cite{dpor} is a technique for dynamically deciding which
    traces will not be interesting based on thread interactions, and
    so greatly reducing the search space. This would increase testing
    performance, and make feasible the testing of large programs.

  \item In practice, schedulers are biased towards a particular subset
    of the possible schedules. They may try to guarantee fairness, for
    example. At the cost of less complete results, schedules which are
    not sufficiently fair could be ignored, reducing the search space.
\end{itemize}

Despite these limitations, our tool solves a problem, and makes
writing reliable Haskell programs a little easier.

\section{Search Party}
\label{sec:prelims-searchparty}

\subsection{Introduction}
\label{sec:prelims-searchparty-intro}

Generate-and-test computations are very common in functional programs,
whether these be in the form of generating and testing statements in
list comprehensions, or chained calls to \verb|map| and
\verb|filter|. Although Haskell compilers generating sequential code
are now very good at optimising this sort of thing, the opportunity
for parallelism is enticing.

List comprehensions are only one facet of generate-and-test problems,
however. Searches which return a successful result, if one exists,
from a pool of candidates can be regarded as a non-deterministic
generate-and-test. Sometimes this nondeterministic result itself may
be required, in which case the computation falls into \verb|IO|, but
other times merely the presence or absence of a result must be known,
restoring determinism.

This paper presents a monad for search computations, which can either
return the first successful result, or any successful result
nondeterministically, with the constraint that \textit{if} a
successful result exists, \textit{one} will definitely be returned. A
generalisation is then developed to produce a stream of all such
results.

For example, we can find (nondeterministically) a perfect number:

\begin{minted}{haskell}
perfect :: IO Integer
perfect = runFind $ [1..] ! isperfect
  where
  isperfect n =
    sum [x | x <- [1..n - 1], n `rem` == 0] == n
\end{minted}
%$

\subsection*{Contributions}

We make the following contributions:

\begin{itemize}
  \item a new library called Search
    Party\footnote{\url{https://github.com/barrucadu/search-party}}
    for lazy parallel search;

  \item several illustrative examples of varying complexity;

  \item benchmark results showing how the library performs.
\end{itemize}

\subsection*{Roadmap}

The rest of the section is organised as follows:

\begin{itemize}
  \item \sect{prelims-searchparty-api} presents the API of the library developed, explaining
    the semantics of the operations.

  \item \sect{prelims-searchparty-impl} discusses the implementation, including the
    complete implementation of a parallel worker.

  \item \sect{prelims-searchparty-examples} shows how Search Party has been applied to a
    small number of existing programs. Benchmark results for both time and space
    under varying degrees of parallelism are also displayed, compared
    with the original programs.

  \item \sect{prelims-searchparty-related} discusses related work, such as the Par
    monad\cite{par} and how this work differs.

  \item \sect{prelims-searchparty-concs} summarises the work done and draws conclusions.
\end{itemize}

\subsection{The \texttt{Find} Monad}
\label{sec:prelims-searchparty-api}

The goal of this work is to provide a parallel abstraction over
generate-and-test powerful enough to handle many instances of this
pattern. The interface is structured around a monad, \verb|Find|:

\begin{minted}{haskell}
newtype Find a
instance Functor     Find
instance Applicative Find
instance Alternative Find
instance Monad       Find
instance MonadPlus   Find
instance Monoid o => Monoid (Find o)
\end{minted}

Results in the \verb|Find| monad can be extracted with \verb|runFind|:

\begin{minted}{haskell}
runFind :: Find a -> IO (Maybe a)
\end{minted}

As can be seen from the type, a \verb|Find a|\footnote{\texttt{Find}
  is actually also parametrised by the underlying concurrency monad,
  using the \texttt{MonadConc} typeclass from \dejafu{}, which allows
  testing. IO and the standard concurrency primitives are used here
  for simplicity of presentation.} value represents a computation
that, when executed, might \textit{fail}.

The intuition behind the \verb|Find| monad is:

\begin{itemize}
  \item if there is a solution, we want one;

  \item if there are multiple solutions, we don't care which we get;

  \item as searching may be expensive, parallelism should be exploited
    as much as possible.
\end{itemize}

There are also some functions to extract results using
\verb|unsafePerformIO|:

\begin{minted}{haskell}
hasResult :: Find a -> Bool
toMaybe   :: Find a -> Maybe a
\end{minted}

Note that \verb|toMaybe| is only pure if the result found is
deterministic.

A \verb|Find| computation is defined in terms of work items, which are
explored in parallel. The Functor and Applicative instances preserve
parallelism by deferring blocking on a result until it is actually
required. The magic happens in the Applicative \verb|<*>| operator:

\begin{minted}{haskell}
(Find mf) <*> (Find ma) = Find $ do
  -- Begin computing 'f' and 'a' in parallel.
  f <- mf
  a <- ma

  -- Block until they are both done, or until
  -- one fails.
  successful <- blockOn [void f, void a]

  if successful
  then do
    -- Extract the results
    fres <- unsafeResult f
    ares <- unsafeResult a

    -- Return the result
    workItem' . Just $ fres ares

  else workItem' Nothing
\end{minted}

Similarly to Haxl\cite{haxl}, both sides of the \verb|<*>| are
explored in parallel for a result, rather than the traditional
approach which would examine the first argument and then the
second. Binding the monadic value inside the \verb|Find| newtype
begins the parallel search for a result. The \verb|blockOn| function
blocks until one of the provided work items fails, or until all
succeed. As this computation is wrapped up inside a \verb|Find|, it
will not be executed until the result is demanded.

The Alternative and MonadPlus instances correspond to a
nondeterministic choice if both arguments succeed, and the Monoid
instance \verb|mappend|s the results together.

The basic building-blocks for \verb|Find| computations are
\verb|oneOf|, \verb|success|, and \verb|failure|, which together allow
transforming a sequential search into a parallel one, by returning a
successful result nondeterministically:

\begin{minted}{haskell}
oneOf   :: Foldable t  => t (Find a) -> Find a
success :: a -> Find a
failure :: Find a
\end{minted}

From these, many combinators can be derived, such as \verb|!| (so
called because it is a kind of indexing operation), and \verb|?|
(because it's a kind of indexing operation using \verb|Maybe|):

\vfill
\begin{minted}{haskell}
(!) :: Foldable t  => t a -> (a -> Bool) -> Find a
as ! p = oneOf . map p' $ toList as where
  p' a = if p a then success a else failure

(?) :: Foldable t => t a -> (a -> Maybe b) -> Find b
as ? f = oneOf . map f'  $ toList as where
  f' = maybe failure success . f
\end{minted}

\subsubsection{Generalising to \texttt{Stream}s}
\label{sec:prelims-searchparty-api-stream}

A natural progression from finding a single successful result is to
find \textit{all} such results:

\begin{minted}{haskell}
allOf :: Foldable t => t (Find a) -> IO (Stream a)
\end{minted}

A \verb|Stream| is like a \verb|Find| which contains multiple
values.

\begin{minted}{haskell}
newtype Stream a
instance Functor     Stream
instance Applicative Stream
\end{minted}

\noindent where the Applicative instance zips two \verb|Stream|s
together with \verb|($)|.

For example, we can find all perfect numbers:

\begin{minted}{haskell}
perfect :: [Integer]
perfect = toList $ [1..] >! isperfect
  where
  isperfect n =
    sum [x | x <- [1..n - 1], n `rem` == 0] == n
\end{minted}
%$

Naturally, \verb|Stream|s can be read from, which has the side-effect
of removing the head element:

\begin{minted}{haskell}
readStream :: Stream a -> IO (Maybe a)
\end{minted}

Where the result is deterministic, a \verb|Stream| can also be turned
into a lazy list,

\begin{minted}{haskell}
toList       :: IO (Stream a) -> [a]
unsafeToList :: Stream a -> [a]
\end{minted}

The \verb|unsafeToList| function is so called because it combines
side-effectful reading with \verb|unsafePerformIO| internally. It is
only safe, then, if the \verb|Stream| is \textit{never used again}
after passing it to \verb|unsafeToList|. The \verb|toList| function is
safer as, rather than taking a \verb|Stream| directly, it takes a
computation which produces a \verb|Stream|.

A \verb|Stream| does not ``wrap up'' a concurrent computation, and as
reading from a stream has a monadic side-effect, \verb|Stream| as it
currently is cannot have a Monad instance. This does not seem to be a
hindrance in practice, as the main use of \verb|Stream| has been in
parallelising list comprehensions.

\subsubsection{Regaining Determinism}
\label{sec:prelims-searchparty-api-det}

Both \verb|Find| and \verb|Stream| have functions to extract results
which are only pure when the result is deterministic. So far the
presented functions can only be deterministic if there is a single
successful result, in which case the distinction between \verb|Find|
and \verb|Stream| is rather meaningless!

Determinism can be restored, however, by returning results in the
order that they appear in the \verb|Foldable.toList| enumeration of
their container. In the case of \verb|Find| this means returning the
first successful result \textit{in the list}, rather than the first
successful result \textit{to finish computing}. Two new basic
functions are thus provided:

\begin{minted}{haskell}
firstOf   :: Foldable t => t (Find a) -> Find a
orderedOf :: Foldable t => t (Find a) -> IO (Stream a)
\end{minted}

Unfortunately, this ordering property, which is needed to produce a
deterministic result, requires additional synchronisation between
parallel workers, and so introduces additional blocking. This is why
the nondeterministic functions are still provided, as they may be
faster.

\subsection{Implementation}
\label{sec:prelims-searchparty-impl}

A \verb|Find| computation is defined in terms of work items, where a
work item contains a \textit{future} result, along with a monadic
action to terminate the computation early.

\begin{minted}{haskell}
newtype Find a = Find
  { unFind :: IO (WorkItem a) }

newtype WorkItem a = WorkItem
  { unWrap :: forall x. WorkItem' x a }

data WorkItem' x a = WorkItem'
  { _result :: TMVar (Maybe x)
  , _mapped :: x -> a
  , _killme :: IO ()
  }

result :: WorkItem a -> IO (Maybe a)
result f = fmap (_mapped $ unWrap f) `liftM` res
  where
  res = atomically . readTMVar . _result $ unWrap f
\end{minted}

The \verb|_mapped| value allows a stored function to be applied
to the result when it is demanded. The \verb|_killme| value allows
a stored action to terminate the parallel computation before it
completes.

The purpose of the existential quantification wrapping the
\verb|WorkItem'| is to prevent the type variable in \verb|_result|
from propagating outwards. The type of the result doesn't matter, as
long as there is a function to convert it to a known type.

The scheduler, when invoked, takes a Boolean indicating whether to
produce a \verb|Stream| or a \verb|Find|; a Boolean indicating whether
the values returned should be in-order; a list of
\verb|IO (WorkItem a)| values to process; and returns either a
read-only channel, or a \verb|TMVar|. Initial experiments simply used
a \verb|Find [a]| type for streams, but getting a result out of that
requires blocking until the entire list is computed as \verb|>>=| for
IO is strict, which is undesirable. As many worker threads are created
as there are \textit{capabilities} available.

A capability is an opportunity for true parallelism. For example, a
single quad-core processor has up to four capabilities, depending on
how the program is invoked. The number of capabilities used is a
parameter of the run-time system, and defaults to 1.

The worker threads are implemented with the \verb|explorer| function,
shown in Figures \ref{fig:impl-explorer1} and
\ref{fig:impl-explorern}, which step through the list of work items,
writing results found to an output \verb|TMVar|.

\subsubsection{One capability}
\label{sec:prelims-searchparty-impl-one}

If there is only one capability, there is only one worker, so most
synchronisation can be avoided. This reduces the cost of using Search
Party, but as seen in Figure \ref{fig:examples-time}, it is not
eliminated entirely. The remaining overhead is due to how results are
communicated to the consumer. In a sequential list-using computation,
once a result has been computed it is available to the consumer very
cheaply. Search Party sends all results through \verb|TMVar|s, which
involves STM, an additional cost which is not involved at all in the
sequential case.

\begin{figure}[t]
  \centering
  \begin{minted}{haskell}
explorer looping _ 1 items wf _ liveworkers var = do
  work <- atomically $ readTVar items
  loop work
  atomically $ writeTVar liveworkers 0

  where
  loop ((item,_):rest) =
    item >>= result >>= maybe (loop rest) (\a -> do
      atomically . putTMVar var $ wf a
      when looping $ loop rest)

  loop [] = return ()
  \end{minted}
  \caption{\texttt{explorer} function for one capability}
  \label{fig:impl-explorer1}
\end{figure}

In Figure \ref{fig:impl-explorer1}, two arguments of \verb|explorer|
are ignored, as they are not necessary when there is a single
worker. The remaining arguments are as follows:

\begin{itemize}
  \item \verb|looping| determines whether to keep going after finding
    the first successful result;

  \item \verb|1| is the number of capabilities;

  \item \verb|items| is the list of work items, stored in a
    \verb|TVar|;

  \item \verb|wf| is a function to transform the result prior to
    putting it in the output variable;

  \item \verb|liveworkers| is a \verb|TVar| containing the number of
    worker threads still running, it is used to detect termination
    without finding a result;

  \item \verb|var| is the \verb|TMVar| to store successful results
    in.
\end{itemize}

This one-capability case atomically claims all work items from the
list. It then walks down that list processing work items until it
finds a successful one, which is written to the output variable. In
this case, the result will always be in-order.

\subsubsection{Multiple capabilities}
\label{sec:prelims-searchparty-impl-multi}

With multiple capabilities, additional synchronisation work must be
done when producing an in-order result. If a worker finds a successful
result, it \textit{cannot} communicate that result to the reading
process until \textit{no other worker is processing a work item
  earlier in the list}.

Every argument is used here. The additional ones are:

\begin{itemize}
  \item \verb|inorder| determines whether to produce an in-order
    result;

  \item \verb|caps| is the number of capabilities;

  \item \verb|currently| is a \verb|TVar| of \verb|(Int,Int)| pairs,
    recording the minimum and maximum index of the work items that a
    thread has currently claimed.
\end{itemize}

\subsubsection*{Reducing contention}
\label{sec:prelims-searchparty-impl-multi-contention}

The obvious approach is to have each worker thread claim a single work
item, process it, and then loop. We can provide for in-order results
by simply having a shared mutable list of \verb|Int|s, to record the
index of the work item each thread is currently processing.

Unfortunately, with large numbers of workers (beyond about 8 on the
Amicable Pairs benchmark), the contention over the single shared work
queue greatly reduces performance. One solution is to claim multiple
work items every time the worker runs out. Initial experiments we
tried suggested that claiming as many work items are there are
capabilities worked well.

However if the list is small relative to the number of capabilities,
then there is a risk of loss of parallelism. A single worker may claim
a significant portion of the work, leaving others with nothing to do.

Furthermore, a mere list of \verb|Int|s is no longer sufficient for
producing in-order results, as we now need to know how many
\textit{unprocessed} work items a thread has claimed. As work item
indices are in ascending order, we can instead have a shared list of
\verb|(Int, Int)|, representing the minimum and maximum indices a
thread has claimed.

The current version of Search Party claims an increasing number of
work items on every iteration, up to the number of capabilities. This
then makes the main loop take a list of numbers of items to claim,

\begin{minted}{haskell}
explorer ... = loop ([1..caps] ++ repeat caps) []
\end{minted}

\subsubsection*{The main loop}
\label{sec:prelims-searchparty-impl-multi-loop}

\begin{figure}[t]
  \centering
  \begin{minted}{haskell}
loop (n:ns) [] = do
  items <- atomically $ do
    witems <- readTVar items

    case splitAt n witems of
      ([], []) -> return Nothing

      (mine, rest) -> do
        writeTVar items rest
        when inorder $ modifyTVar'' currently claim
        return $ Just mine

  maybe (atomically retire) (loop ns) items

  where
  claim  = ((snd $ head mine, snd $ last mine):)
  retire = modifyTVar' liveworkers $ subtract 1
  modifyTVar'' tvar = modifyTVar' tvar . force

loop n ((item, idx):rest) = do
  fwrap  <- item
  maybea <- result fwrap

  case maybea of
    Just a -> do
      atomically $ do
        when inorder $ readTVar currently >>= block

        putTMVar var $ wf a
        when inorder unclaim

        unless looping retire
      when looping $ loop n rest
    _ -> do
      atomically $ when inorder unclaim
      loop n rest

  where
  block = check . all ((>=idx) . fst)
  retire = modifyTVar' liveworkers $ subtract 1
  \end{minted}
  \caption{\texttt{explorer} loop for multiple capabilities}
  \label{fig:impl-explorern}
\end{figure}

The main loop is displayed in Figure \ref{fig:impl-explorern}. There
are two cases to consider.

If the worker runs out of work, more must be claimed. If no work items
can be claimed, the worker decrements \verb|liveworkers| variable, and
terminates. The use of a hyper-strict \verb|modifyTVar''| here
prevents a large build-up of thunks in the heap, which caused
excessive garbage collection and greatly reduced performance when
there were more than about 4 workers.

If the worker still has work to do, the main loop is a simple
recursion down this list. The only complications arising from in-order
results. Upon finding a successful result, if in-order results are
required, the worker blocks until every other worker is working on a
work item with a higher index. It also notifies every other worker
when it is done with a work item. Here \verb|unclaim| updates the
shared list of work items every thread owns. As all workers share the
same output \verb|TMVar|, workers may be holding on to a successful
result, waiting for this variable to be read. The effect is to build
up a small buffer of results which can be read in quick succession
without needing to wait.

\subsection{Examples and Performance}
\label{sec:prelims-searchparty-examples}

% This is here to make it appear at the top of the examples page.
\begin{figure*}[ht]
  \centering
  \begin{tabularx}{\textwidth}{|r|X|X|X|X|X|X|X|}
    \hline & \multicolumn{7}{c|}{\textbf{Version}}\\
    \hline \cen\textbf{Program} & \cen\textbf{Original}
                                & \cen\textbf{-N1}
                                & \cen\textbf{-N2}
                                & \cen\textbf{-N4}
                                & \cen\textbf{-N8}
                                & \cen\textbf{-N16}
                                & \cen\textbf{-N24}\\

    \hline Amicable Pairs & 179s (1x)
                          & 222s (0.8x)
                          & 134s (1.3x)
                          & 72.1s (2.5x)
                          & 39.2s (4.6x)
                          & 28.6s (6.3x)
                          & 26.8s (6.7x)\\

           Mate-in-N      & 20.9s (1x)
                          & 21.3s (1.0x)
                          & 11.5s (1.8x)
                          & 7.8s (2.7x)
                          & 6.4s (3.3x)
                          & 6.5s (3.2x)
                          & 7.0s (3.0x)\\

        %  CountDown (sols) & 22.4s (1x)
        %                   & 25.9s (0.9x)
        %                   & 14.8s (1.5x)
        %                   & 8.6s (2.6x)
        %                   & 6.8s (3.3x)
        %                   & 7.6s (2.9x)
        %                   & 9.2s (2.4x)\\
        % CountDown (sols') & 1.67s (1x)
        %                   & 2.5s (0.7x)
        %                   & 1.5s (1.4x)
        %                   & 0.89s (1.9x)
        %                   & 0.73s (2.3x)
        %                   & 0.84s (2.0x)
        %                   & 1.1s (1.5x)\\
               CountDown  & 0.49s (1x)
                          & 0.55s (0.9x)
                          & 0.35s (1.4x)
                          & 0.21s (2.3x)
                          & 0.16s (3.1x)
                          & 0.16s (3.1x)
                          & 0.18s (2.7x)\\

           Iso. Checker   & 1.70s (1x)
                          & 2.27s (0.8x)
                          & 1.51s (1.1x)
                          & 0.78s (2.2x)
                          & 1.33s (1.3x)
                          & 5.61s (0.3x)
                          & 8.31s (0.2x)\\
    \hline
  \end{tabularx}  
  \caption{Benchmark timing results, with the Search Party version
    executed with differing numbers of threads.}
  \label{fig:examples-time}
\end{figure*}

We now present some applications of Search Party to existing programs,
ranging from the very simple (enumerating amicable pairs) to the
complex (solving the mate-in-n problem for a given chess problem).

We benchmarked on a machine with 4 AMD Opteron 6134 8-core processors
at 2.3GHz, for a total of 32 cores. The OS was Ubuntu 14.04, using GHC
7.6.3 with no optimisation flags. All timing results were averaged
over 10 runs.

Timing results and speed-up under differing degrees of parallelism are
displayed in Figure \ref{fig:examples-time}. For some benchmarks,
memory use of original and modified programs (with -N4) are displayed
in Figure \ref{fig:examples-space}. As can be seen, the Search Party
versions of the benchmarks consume more memory, but the usage is not
as consistent. This is because of the induced producer-consumer
pattern, as seen in the blocking behaviour of workers in \sect{prelims-searchparty-impl}.

Of particular interest are the benchmark results for the most
optimised variant of Hutton's Countdown solver. This is a hand-tuned,
simple, program: it is even used as an example of how program
transformations can be used for great performance gains! Even so, the
Search Party version is able to outperform the original by a factor of
three on eight cores, with no domain-specific optimisation to the
parallelism.

\begin{figure*}[t]
  \centering
  \begin{subfigure}{0.4\textwidth}
    \includegraphics[width=\textwidth]{space/amis-orig.eps}
    \caption{Amicable Pairs}
    \label{fig:examples-space:amis-orig}
  \end{subfigure}
  \begin{subfigure}{0.4\textwidth}
    \includegraphics[width=\textwidth]{space/amis-sp}
    \caption{Amicable Pairs (Search Party)}
    \label{fig:examples-space:amis-sp}
  \end{subfigure}

  % \begin{subfigure}{0.4\textwidth}
  %   \includegraphics[width=\textwidth]{space/mate-orig}
  %   \caption{Mate-in-N}
  %   \label{fig:examples-space:mate-orig}
  % \end{subfigure}
  % \begin{subfigure}{0.4\textwidth}
  %   \includegraphics[width=\textwidth]{space/mate-sp}
  %   \caption{Mate-in-N (Search Party)}
  %   \label{fig:examples-space:mate-sp}
  % \end{subfigure}

  \begin{subfigure}{0.4\textwidth}
    \includegraphics[width=\textwidth]{space/sols-orig}
    \caption{sols}
    \label{fig:examples-space:sols-orig}
  \end{subfigure}
  \begin{subfigure}{0.4\textwidth}
    \includegraphics[width=\textwidth]{space/sols-sp}
    \caption{sols (Search Party)}
    \label{fig:examples-space:sols-sp}
  \end{subfigure}

  \begin{subfigure}{0.4\textwidth}
    \includegraphics[width=\textwidth]{space/sols2-orig}
    \caption{sols'}
    \label{fig:examples-space:sols2-orig}
  \end{subfigure}
  \begin{subfigure}{0.4\textwidth}
    \includegraphics[width=\textwidth]{space/sols2-sp}
    \caption{sols' (Search Party)}
    \label{fig:examples-space:sols2-sp}
  \end{subfigure}

  % \begin{subfigure}{0.4\textwidth}
  %   \includegraphics[width=\textwidth]{space/sols3-orig}
  %   \caption{sols''}
  %   \label{fig:examples-space:sols3-orig}
  % \end{subfigure}
  % \begin{subfigure}{0.4\textwidth}
  %   \includegraphics[width=\textwidth]{space/sols3-sp}
  %   \caption{sols'' (Search Party)}
  %   \label{fig:examples-space:sols3-sp}
  % \end{subfigure}

  % \begin{subfigure}{0.4\textwidth}
  %   \includegraphics[width=\textwidth]{space/iso-orig}
  %   \caption{Iso. Checker}
  %   \label{fig:examples-space:iso-orig}
  % \end{subfigure}
  % \begin{subfigure}{0.4\textwidth}
  %   \includegraphics[width=\textwidth]{space/iso-sp}
  %   \caption{Iso. Checker (Search Party)}
  %   \label{fig:examples-space:iso-sp}
  % \end{subfigure}

  \caption{Benchmark memory results, with the Search Party version
    executed with 4 threads.}
  \label{fig:examples-space}
\end{figure*}

\subsection*{Amicable Pairs}
\label{sec:prelims-searchparty-examples-amis}

An \textit{amicable pair} is a pair of numbers such that the sum of
the proper divisors of each equals the other. For example, $(220,
284)$ is an amicable pair, as we have:

\begin{align*}
  D(220) &= \left\{1,~2,~4,~5,~10,~11,~20,~22,~44,~55,~110\right\}\\
  D(284) &= \left\{1,~2,~4,~71,~142\right\}\\
  220    &= 1 + 2 + 4 + 71 + 142\\
  284    &= 1 + 2 + 4 + 5 + 10 + 11 + 20 + 22 + 44 + 55 + 110
\end{align*}

Where $D(x)$ here is the set of proper divisors of $x$. This benchmark
enumerates and prints the first 100 amicable pairs. We can enumerate
the set of amicable pairs with a list comprehension:

\begin{minted}{haskell}
amicablePairs :: [(Integer, Integer)]
amicablePairs =
  [ (n, sn)
  | n <- [2..]
  , let sn = sigmaBar n
  , sn > n
  , sigmaBar sn == n]
\end{minted}

\noindent where \verb|sigmaBar| computes this divisor sum. To avoid
duplication, the elements of each pair are in ascending order.

Initially pairs are found very quickly, but the pace of enumeration
slows towards the end. As \verb|amicablePairs| is a generate-and-test
computation with a simple generator and a more complex test, we aim to
derive a new version using Search Party.

We can obtain it by a fairly mechanical translation of the original:

\begin{enumerate}
  \item Split the implicit \verb|filter| out of the comprehension,
\begin{minted}{haskell}
amicablePairs =
  filter (\(n,sn) -> sn > n && sigmaBar sn == n)
  [(n,sigmaBar n) | n <- [2..]]
\end{minted}

  \item Factor out the predicate,
\begin{minted}{haskell}
amicablePairs =
  filter ami [(n,sigmaBar n) | n <- [2..]]
  where
  ami (n, sn) = sn > n && sigmaBar sn == n
\end{minted}

  \item Turn the \verb|filter| into an \verb|inOrder|,
\begin{minted}{haskell}
amicablePairs =
  inOrder ami [(n,sigmaBar n) | n <- [2..]]
  where
  ami (n, sn) = sn > n && sigmaBar sn == n
\end{minted}

  \item Replace \verb|inOrder| with \verb|>!|, which is just
    \verb|flip inOrder|,
\begin{minted}{haskell}
amicablePairs =
  [(n,sigmaBar n) | n <- [2..]] >! ami
  where
  ami (n, sn) = sn > n && sigmaBar sn == n
\end{minted}

  \item Convert the \verb|Stream| back into a list,
\begin{minted}{haskell}
amicablePairs =
  toList $ [(n,sigmaBar n) | n <- [2..]] >! ami
  where
  ami (n, sn) = sn > n && sigmaBar sn == n
\end{minted}
\end{enumerate}
%$

This final version isn't too dissimilar to the \verb|filter| version
in step 2. In fact, we could have stopped in step 3, had we added a
call to \verb|toList| as well. As can hopefully be seen, for list
comprehensions with a single generator, the introduction of
parallelism is quite simple.

\begin{figure}[t]
  \centering
  \begin{tabularx}{\linewidth}{|X|X|X|X|}
    \hline \textbf{Version} & \textbf{Optimum} & \textbf{Actual} & \\
    \hline -N1  & 179s (1x)   & 222s (0.8x)  & 0.8x \\
           -N2  & 89.5s (2x)  & 134s (1.3x)  & 0.7x \\
           -N4  & 44.8s (4x)  & 72.1s (2.5x) & 0.6x \\
           -N8  & 22.4s (8x)  & 39.2s (4.6x) & 0.6x \\
           -N16 & 11.2s (16x) & 28.6s (6.3x) & 0.4x \\
           -N24 & 7.5s  (24x) & 26.8s (6.7x) & 0.3x \\
    \hline
  \end{tabularx}
  \caption{Optimal speed-ups for Amicable Pairs}
  \label{fig:examples-amis-amdahl}
\end{figure}

Figure \ref{fig:examples-amis-amdahl} shows optimal speed-ups for this
benchmark, calculated using Amdahl's law after profiling revealed a
negligible proportion of overall execution time sequentially consuming
the list. The entire \verb|amicablePairs| comprehension, rather than
just the explicit tests, was profiled. Due to lazy evaluation,
parallelisation of the test also parallelises the generation to some
extent.

\subsection*{Mate-in-N}
\label{sec:prelims-searchparty-examples-mate}

The applicability of Search Party depends on the overall structure of
a computation including a generate-and-test search. There is some
sequential prefix doing some set-up, a period amenable to parallelism,
and then a sequential suffix producing the final result. Ideally, the
sequential prefix and suffix are very small compared to the parallel
middle. This was certainly the case in the Amicable Pairs example.

In the Mate-in-N benchmark, the prefix and suffix computations are
more significant. This program attempts to solve the Mate-in-N
problem. A chess position is presented where one side can mate the
other in $n$ moves. The challenge is to find a pruned game-tree
demonstrating the win no matter what moves the opponent makes. Here is
an example input to the program (a position that actually arises in
Kohtz v. Kockelkorn, 1875):

\begin{verbatim}
- - - - - - - K 
- - - - - - - - 
- - - - - n - p 
- - - - - - - - 
- - - - - - - - 
- - - - - B P - 
- - - - - - - - 
b - - - - - k - 

White to move and mate in 5
\end{verbatim}

Due to differing difficulties, timing results were averaged over 10
different problems.

The program is structured as generating a game tree, which can be done
in parallel, but then pruning it sequentially to produce a minimal
tree.

The introduction of parallelism is a little more complex than in the
Amicable Pairs, using an additional function parameter to prevent
nested parallelism, which Search Party currently does not cope well
with.

\vspace{1cm}
The original definition

\begin{minted}{haskell}
solution :: Board -> Colour -> Int -> Maybe Solution
solution bd c n | n > 0 = 
  let mds = moveDetailsFor c bd
  in foldr solnOr Nothing mds
\end{minted}

\noindent is altered as follows.

\begin{minted}{haskell}
solution :: Bool
         -> Board -> Colour -> Int -> Maybe Solution
solution top bd c n | n > 0 = 
  let mds = moveDetailsFor c bd
  in if top
     then toMaybe $ mds .? (flip solnOr Nothing)
     else foldr solnOr Nothing mds
\end{minted}
%$

The \verb|top| parameter indicates whether this is a ``top-level
search'', or a search begun when constructing some lower level of the
game tree. The candidate solutions for parallel exploration correspond
to the possible initial moves.

\begin{figure}[t]
  \centering
  \begin{tabularx}{\linewidth}{|X|X|X|X|}
    \hline \textbf{Version} & \textbf{Optimum} & \textbf{Actual} & \\
    \hline -N1  & 20.9s (1.0x) & 21.3s (1.0x) & 1.0x \\
           -N2  & 11.6s (1.8x) & 11.5s (1.8x) & 1.0x \\
           -N4  & 6.9s (3.0x)  & 7.8s (2.7x)  & 0.8x \\
           -N8  & 4.6s (4.6x)  & 6.4s (3.3x)  & 0.7x \\
           -N16 & 3.4s (6.2x)  & 6.5s (3.2x)  & 0.5x \\
           -N24 & 3.0s (7.0x)  & 7.0s (3.0x)  & 0.4x \\
    \hline
  \end{tabularx}
  \caption{Optimal speed-ups for Mate-in-N}
  \label{fig:examples-mate-amdahl}
\end{figure}

Figure \ref{fig:examples-mate-amdahl} shows optimal speed-ups for this
benchmark, assuming that 89.4\% of the work could be
parallelised. This is optimistic, as it assumes every (recursive) call
to \verb|solution| could be executed in parallel. Search Party is not
suitable for expressing this sort of recursive generation of new work,
as it does not currently share worker threads. As the result of the
computation is finite and used in full, the Par monad may be a more
viable approach here.

\subsection*{Hutton's Countdown Solver}
\label{sec:prelims-searchparty-examples-hutton}

\textit{Countdown} is a gameshow where one of the components is a
number game. Contestants choose a collection of 6 number cards, and
then must get as close as possible to a randomly-generated three-digit
number using only addition, subtraction, multiplication, and
division. Not all numbers must be used, a number may be used as many
times as it appears on the chosen number cards, and all stages of the
calculation must involve integer values.

Graham Hutton produced a series of programs\footnote{Timing results
  for only the most optimal are shown.} to solve the
\textit{Countdown} numbers game\cite{hutton}, with different levels of
intelligence in how the problem was approached. The simplest is just a
brute-force generation of all possible legal expressions; then there
is a version which eliminates invalid solutions more rapidly; and
finally there is a version exploiting arithmetical properties.

The key elements of the three programs are list comprehensions, and
are as follows,

\begin{minted}{haskell}
sols, sols', sols'' :: [Int] -> Int -> [Expr]
sols ns n   = [e | ns' <- choices ns
                 , e   <- exprs   ns'
                 , eval e == [n]]

sols' ns n  = [e | ns'   <- choices ns
                 , (e,m) <- results ns'
                 , m == n]

sols'' ns n = [e | ns'   <- choices  ns
                 , (e,m) <- results' ns'
                 , m == n]
\end{minted}

Where \verb|Expr| is an ADT representing expressions composed of the
operators legal in the game.

One hundred random \verb|(input, target)| pairs were generated, and
the following benchmark constructed,

\begin{minted}{haskell}
main :: IO ()
main = mapM_ (print . length . uncurry solutions) ...
\end{minted}

Timing results are divided by 100, to represent the time taken to
solve an ``average'' \textit{Countdown} challenge.

Parallelising the na\"{\i}ve solution proved to be a little tricky. A
fairly straightforward transformation would be something like:

\begin{minted}{haskell}
sols ns n = parFilter (\e -> eval e == [n]) .
  concatMap exprs $ choices ns
\end{minted}
%$

\noindent where \verb|parFilter| is a function built out of the pieces
we have seen so far. Unfortunately, this performed poorly, and
contention over the list of expressions seemed to be the
problem.

Another version constructs the lists in separate threads and
concatenates at the end.

\begin{minted}{haskell}
sols ns n = concat . parMap go $ choices ns where
  go ns' = [e | e <- exprs ns', eval e == [n]]
\end{minted}
%$

Here \verb|parMap| is defined to evaluate each element of the result
to weak-head normal form, to ensure work is being done in
parallel. This performed better, but still rather slowly. The problem
with this sort of approach is that if any empty lists are produced, we
will waste time concatenating them at the end, sequentially. It would
be preferable to discard empty results in parallel.

This observation lead to a final version:

\begin{minted}{haskell}
sols ns n = concat . go $ choices ns where
  go xs = toList $ xs >? (check . es)
  es ns' = [e | e <- exprs ns', eval e == [n]]

  check [] = Nothing
  check xs = Just xs
\end{minted}

Now, if a choice produces an empty list of expressions, it is
discarded, we only concatenate nonempty lists, and so no time is
wasted on useless results after the parallel computation finishes.

In addition to providing a collection of ``primitive'' functions to
parallelise in terms of \verb|Find| and \verb|Stream|, a part of the
goal of Search Party is to be easy to integrate into existing code.
So functions like \verb|parMap|, \verb|parFilter|, and
\verb|parConcatMap| have been included in the library, to help
approach this goal.

With the insight that the generation of results from choices had to
happen in the parallel threads, producing parallel variants of the two
optimised functions was simple,

\begin{minted}{haskell}
sols'  ns n = parConcatMap
  (\ns' -> [e | (e,m) <- results  ns', m == n]) $
  choices ns

sols'' ns n = parConcatMap
  (\ns' -> [e | (e,m) <- results' ns', m == n]) $
  choices ns
\end{minted}

\begin{figure}[t]
  \centering
  \begin{tabularx}{\linewidth}{|X|X|X|X|}
    \hline \textbf{Version} & \textbf{Optimum} & \textbf{Actual} & \\
    \hline -N1  & 0.49s (1.0x) & 0.55s (0.9x) & 0.9x \\
           -N2  & 0.25s (1.9x) & 0.35s (1.4x) & 0.7x \\
           -N4  & 0.14s (3.6x) & 0.21s (2.3x) & 0.6x \\
           -N8  & 0.08s (6.4x) & 0.16s (3.1x) & 0.5x \\
           -N16 & 0.04s (10x)  & 0.16s (3.1x) & 0.3x \\
           -N24 & 0.04s (13x)  & 0.18s (2.7x) & 0.2x \\
    \hline
  \end{tabularx}
  \caption{Optimal speed-ups for Hutton's Countdown solver}
  \label{fig:examples-hutton-amdahl}
\end{figure}

Figure \ref{fig:examples-hutton-amdahl} shows optimal speed-ups for
this benchmark, assuming all of the work done in the \verb|exprs|,
\verb|eval|, \verb|results| and \verb|results'| functions can be
parallelised. As with the Mate-in-N problem, this is optimistic, due
to the lazy evaluation of the rest of the comprehension.

\subsection*{Isomorphism Checker}
\label{sec:prelims-searchparty-examples-isos}

GP2\cite{gp2} is a nondeterministic programming language based on
graph transformation, and an important component of the reference
interpreter is a program to check if two graphs are isomorphic. The
isomorphism checker first checks that the graphs are the same size,
and then searches for an isomorphism by generating candidate node
morphisms respecting node labels and degrees, testing if a morphism is
a bijection.

The GP2 graph file format is very simple, and by permuting the list of
nodes, different but isomorphic graphs can be produced. 100 random
permutations of a graph containing (disjoint) Sierpinski order 2 and 3
graphs were produced, with timing results averaged over this.

The introduction of parallelism is quite simple:

\begin{minted}{haskell}
isomorphic :: (Ord a, Ord b)
           => Graph a b -> Graph a b -> Bool
isomorphic g1 g2 =
  length ns1 == length ns2 &&
  ( parAny
    (edgesIso g1 g2)
    (bijectionsWith (nodeAttribs g1) ns1
                    (nodeAttribs g2) ns2)
  )
  where
  ns1 = allNodeKeys g1
  ns2 = allNodeKeys g2
\end{minted}

The introduction of a \verb|parAny| (in place of a regular \verb|any|)
is the only change made. As can be seen in Figure
\ref{fig:examples-time} performance begins to fall with more than 4
parallel workers. It is possible that a more sophisticated
introduction of parallelism could have yielded better results, but
this was not pursued.

\begin{figure}[t]
  \centering
  \begin{tabularx}{\linewidth}{|X|X|X|X|}
    \hline \textbf{Version} & \textbf{Optimum} & \textbf{Actual} & \\
    \hline -N1  & 1.7s  (1.0x) & 2.27s (0.7x) & 0.7x \\
           -N2  & 0.91s (1.9x) & 1.51s (1.1x) & 0.6x \\
           -N4  & 0.52s (3.3x) & 0.78s (2.2x) & 0.7x \\
           -N8  & 0.33s (5.3x) & 1.33s (1.3x) & 0.2x \\
           -N16 & 0.22s (7.6x) & 5.61s (0.3x) & 0.03x \\
           -N24 & 0.19s (8.9x) & 8.31s (0.2x) & 0.02x \\
    \hline
  \end{tabularx}
  \caption{Optimal speed-ups for the Isomorphism Checker}
  \label{fig:examples-isos-amdahl}
\end{figure}

Figure \ref{fig:examples-isos-amdahl} shows optimal speed-ups for this
benchmark. The results for $n \geq 8$ are poor. Looking at the source
of \verb|bijectionsWith|, it appears to be very sequentially in its
current incarnation. This imposes unnecessary sequentiality and
blocking when claiming work items, and so much of the benefit of
parallelism is lost.

\subsection{Related Work}
\label{sec:prelims-searchparty-related}

Speculative computation\cite{spec} is, in some sense, the exact
opposite of lazy evaluation. Whereas in most cases, we wish to delay a
computation until its result is demanded, sometimes it can be worth
computing something ahead of time, on the assumption that it is likely
to be needed. Such efforts will be wasted if the assumption proves
incorrect. The cost of \textit{speculating} on such results can be
lessened by performing the evaluation in parallel with the main thread
of control, giving a net gain if the assumption is correct.

GUM\cite{gum} introduces speculative parallelism in Haskell with the
\verb|par| combinator, which starts evaluating its first argument in
parallel and returns its first, and demonstrates a speed-up even with
this primitive operation alone. In contrast, Search Party uses much
more controlled parallelism, with control of the scheduling taken from
the runtime system. This prevents a risk of a large amount of parallel
computation being started at once, which would increase resource
contention, which could happen with liberal application of \verb|par|.

One application of speculative parallelism in Haskell is the work of
Cope, Gent, and Hammond on parallel heuristic search\cite{parsat}
applied to SAT solvers. In this work they produce two sequential SAT
solvers which would be amenable to parallelism, rather than attempt to
produce an optimal sequential solver. Both algorithms include a
splitting step, to turn a problem into two simpler cases. Relative
speed-ups of between 0.92 and 4.8 are obtained by introduction of
parallelism at this splitting step.

A version with explicit speculation support, where the parallel
computation returns a continuation if it executes for too long without
finding a result, performs slightly worse than the naive, more eager,
approach. The authors suggest this may be due to overhead in their
implementation of this mechanism.

The Strategies\cite{strategies} library provides for speculative
computation in Haskell by allowing the programmer to write an
\textit{evaluation strategy}, specifying how some data structure is to
be evaluated. Such strategies may include, for example, evaluating
elements of a list in parallel. The building blocks are \verb|rseq|,
which forces sequential evaluation, and \verb|rpar|, which forces
parallel evaluation.

The \verb|Stream| combinators of Search Party are very much in a
speculative style: values not yet requested by the programmer are
being searched for in parallel, on the assumption that they are
\textit{likely} to be needed. Unlike Strategies, the parallelism is
much more precisely controlled: the number of parallel agents is
fixed, and the agents block if results are not demanded. The
\verb|Stream| combinators can be thought of as variants on a parallel
\verb|mapMaybe| operation, which could be implemented na\"{\i}vely
with Strategies as follows.

\begin{minted}{haskell}
import Control.Parallel.Strategies
parMapMaybe :: (a -> Maybe b) -> [a] -> [b]
parMapMaybe f = catMaybes . parMap rseq f
\end{minted}

However the Strategies \verb|parMap| sparks off each element of the
list at once, resulting in a potentially huge degree of
parallelism. This in turn can lead to more contention over resources,
and lowered performance. A work-around, then, might be to introduce
chunking,

\begin{minted}{haskell}
parMapMaybe f = withStrategy (parListChunk 16 rseq)
              . map f
\end{minted}

But what should the chunk size be? Furthermore, with an infinite list,
this will still result in a great number of sparks. As there is no way
to check if a value has been evaluated, there is no way for the
programmer to keep the number of parallel agents constant, or to pause
work if the agents are producing new results significantly more
quickly than they are being demanded.

The \verb|Par| monad\cite{par} provides for deterministic parallelism,
and so might be seen as an obvious candidate to use, rather than the
deterministic \verb|Find| and \verb|Stream| combinators. However, as
noted, relaxing the requirement of determinism can be faster in some
cases.

Gaining a speed-up with parallelism necessarily requires doing work in
separate threads, which laziness can thwart. The \verb|Par| monad is
fully strict by default. Using Search Party to map a function over a
list in parallel requires careful forcing of values. For example, the
\verb|parMap| and \verb|parConcatMap| functions evaluate results to
WHNF in parallel. This sadly means that the convenience functions
provided in Search Party are \textit{not} a drop-in replacement for
the standard list-processing functions in the presence of $\bot$s, as
can be seen in this simple example:

\begin{minted}{haskell}
bad = null . parMap (\_ -> last [1..])
\end{minted}

Here, \verb|bad [1,2,3]| is $\bot$, whereas if \verb|map| were used
instead, the result would be \verb|False|.

Perhaps nondeterminism is over-rated. Most programmers would only use
a library like Search Party to parallelise list comprehensions and
similar pure computations. Even here, the \verb|Par| monad may not be
suitable, as when a \verb|Par| computation terminates, all parallelism
must be complete, consider:

\begin{minted}{haskell}
import Control.Monad.Par
parMapMaybe f = catMaybes . runPar . parMap f
\end{minted}

This \verb|parMap| function spawns one thread for every element of the
list, but as we \textit{do} know if a thread has finished with
\verb|Par|, we can rewrite this to refrain from spawning new threads
until they are needed. The problem is that no such function will
terminate until the \textit{entire} list has been processed. In the
case of an infinite list, then, the result is $\bot$.

\subsection{Conclusions}
\label{sec:prelims-searchparty-concs}

We have presented a new library for parallel generate-and-test style
computations, and demonstrated that it can give a significant speed-up
over the sequential case. Furthermore, we have shown that it is not
feasible to achieve the same flexibility as Search Party with
Strategies or the \verb|Par| monad.

Parallelism and concurrency are generally seen as worthwhile tools to
apply to large problems. Because of the difficulty of correctly using
them, applying them to small problems is often simply not
considered. However, we have shown here that this ``parallelism in the
small'' \textit{can} and \textit{does} offer improved performance, and
so should be considered also.

Concurrent Search Party computations currently receive no special
treatment. Worker threads are created for all computations, and may
contend over execution time. This can be seen in the applicative
instance for \verb|Find|, but also arises with nested Search Party
computations. A solution worth pursuing would have a global pool of
workers which all computations share.
