\part{Introduction}

% "identify and describe in outline your chosen field or research;
% explain the motivation for research in that field."

\chapter{Introduction}
\label{chp:intro}

My research is concerned with the problems of nondeterministic
concurrency in lazy pure functional programming languages, and how to
wield this powerful tool whilst avoiding possibly subtle programming
errors.

Concurrency is notoriously difficult to get right\cite{overrated},
sometimes even leading to death\cite{therac25}. The problem largely
stems from the nondeterminism of scheduling, the same program with the
same inputs may produce different results depending on the schedules
chosen at runtime. This makes it difficult to use traditional testing
techniques with concurrent programs, and to spot potentially flawed
code when reading it. These ``Heisenbugs'' make it difficult to be
confident of the correctness of concurrent programs: no bug has been
observed during the testing process, but how do we \textit{know} that
there aren't any?

There are now a few well-known techniques to avoid concurrency bugs,
such as protecting mutable state with locks, and acquiring locks in a
fixed order. Exercises like the Dining
Philosophers\cite{diningphilosophers} and the Santa Claus
Problem\cite{santaclaus} allow programmers to explore these topics in
small well-understood settings. However, as systems grow, it becomes
difficult to think about how different components interact, and it is
easy to slip up and introduce a bug.

\textit{Systematic concurrency testing} (SCT)\cite{pbound, dbound,
  empirical, heisenbugs} is a technique for avoiding the problem of
nondeterminism when writing tests. It aims to test a large number of
schedules, whilst typically also making use of local knowledge of the
program to reduce the number of schedules needed to be confident of an
accurate result. By testing many schedules, we can be confident that
any bugs which have not been found are unlikely to be exhibited.

\section{Parallelism vs. Concurrency}
\label{sec:intro-parconc}

It is worth clarifying at this early stage some terminology which will
be frequently used throughout this report:

\begin{description}
  \item[Concurrency] is a programming methodology, using concepts such
    as threads, locks, and mutable variables to structure
    programs.

  \item[Parallelism] is an implementation detail, where a multiplicity
    of hardware components are used to execute distinct pieces of code
    simultaneously.
\end{description}

Concurrency does not require parallelism, as demonstrated by the
single-core, single-processor computers of yore. Similarly,
parallelism does not require concurrency, as demonstrated by the
\verb|par| combinator in Haskell, which evaluates its arguments in
parallel.

Unrestricted concurrency is explicit and semantically
visible\cite{concurrent}. The interleaved execution of threads, when
combined with mutable state, gives rise to nondeterminism. Semaphores
and locks give rise to nontermination in the form of deadlock and
livelock. Parallelism, in particular the parallel evaluation of
expressions, is semantically invisible, and there is the possibility
for implicit parallelism, ``at present these combinators [\verb|par|
and \verb|seq|] are added by the programmer, though we would of course
like this task to be automated.''\cite{gum}

Concurrency is often implemented using parallelism, and indeed a
concurrency abstraction can be used to guarantee parallelism (given
suitable hardware), for example by having the ability to restrict the
execution of individual threads to given processors.

This report is largely concerned with concurrency, although
parallelism is also discussed as it is often the motivation to use
concurrency.

\section{Testing Concurrency}
\label{sec:intro-sct}

The problem of testing concurrent programs is that the scheduler is a
part of the language runtime (or the operating system), and so out of
the reach of the programmer and tester. SCT overcomes this problem by
forcing a concurrent program to instead use a scheduler implemented as
part of the testing framework: either by overriding the concurrency
primitives of the language (as in LazyLocks\footnote{(Paul Thompson) to
  appear}), or by modifying the program under test to call out to this
new scheduler (as in PULSE\cite{pulse}).

Once the scheduler is under control, schedules can be recorded and
replayed, giving reproducibility. Furthermore, by observing which
scheduling decisions are available at each decision point, possible
schedules can be systematically explored, making different decisions
on subsequent executions. Common methods of choosing schedules to take
are random, pre-emption bounding\cite{pbound}, and delay
bounding\cite{dbound}.

\begin{description}
  \item[Random] scheduling is just that, at each decision point a
    random decision is made. No guarantees about completeness of lack
    of wasted work are made.

  \item[Pre-emption bounding] explores all schedules with $n$
    pre-emptions, where a pre-emption is a context switch (a change
    from one thread to another) where the original thread was not
    blocked. Typically this is iterated with increasing values of $n$,
    to explore all schedules with up to some number of pre-emptions.

  \item[Delay bounding] explores all schedules with $n$ or fewer
    deviations from an otherwise deterministic scheduler.
\end{description}

Iterative pre-emption bounding gives a global property of schedules,
that there are no errors that can be exhibited with $n$ or fewer
pre-emptions, whereas delay bounding gives a result conditional on the
initial choice of deterministic scheduler. Despite this, they both
perform about as well as each other in terms of bug finding
ability\cite{empirical}, and the number of schedules explored by delay
bounding grows more slowly than with pre-emption
bounding\cite{dbound}, perhaps making it a more attractive choice for
during development, with pre-emption bounding reserved for producing
more concrete guarantees ahead of software releases. Random
scheduling, surprisingly, performs about as well as schedule bounding
approaches on a standard collection of SCT benchmarks\cite{empirical}.

SCT is a powerful testing technique for concurrent programs, however
it seems to have received little attention in the world of functional
programming. This is possibly because of the large emphasis on
deterministic parallelism, however as concurrency is still used in
Haskell (often in the implementation of these deterministic
abstractions!), I believe that there is a place for it in the Haskell
world.

\section{Structure of this Report}
\label{sec:intro-outline}

\begin{itemize}
  \item Chapter \ref{chp:litrev} surveys programming technologies for
    nondeterministic concurrency in lazy pure functional programming
    languages. It focuses on libraries for deterministic parallelism
    built atop concurrency, and on testing tools.

  \item Chapter \ref{chp:dejafu} contains a paper submitted to the
    2015 Haskell Symposium\cite{dejafu} on implementing and using
    systematic concurrency testing in Haskell. It presents a
    generalisation of the standard Haskell concurrency API allowing
    testing, and presents a number of examples, including two from
    pre-existing codebases.

  \item Chapter \ref{chp:searchparty} contains a paper submitted to
    the 2015 Haskell Symposium\cite{searchparty} on parallelising
    generate-and-test computations by making use of deterministic
    concurrency. The chapter uses the standard concurrency API for
    ease of presentation, but the real implementation uses \dejafu{}
    for testing purposes.

  \item Chapter \ref{chp:proposal} outlines a proposal for a research
    programme. Both short- and long-term goals are identified and a
    strategy for reaching them is discussed.
\end{itemize}
